{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"crawler/about/","text":"\u00dcber den Crawler Der Crawler ist daf\u00fcr zust\u00e4ndig die Bundestagswebseite in regelm\u00e4\u00dfigen Abst\u00e4nden auf neu ver\u00f6ffentlichte Reden zu \u00fcberpr\u00fcfen, diese herunterzuladen, durch externe Anwendungen Reden aus den Dateien zu extrahieren und diese in das P2P Netzwerk weiterzureichen.","title":"\u00dcber"},{"location":"crawler/about/#uber-den-crawler","text":"Der Crawler ist daf\u00fcr zust\u00e4ndig die Bundestagswebseite in regelm\u00e4\u00dfigen Abst\u00e4nden auf neu ver\u00f6ffentlichte Reden zu \u00fcberpr\u00fcfen, diese herunterzuladen, durch externe Anwendungen Reden aus den Dateien zu extrahieren und diese in das P2P Netzwerk weiterzureichen.","title":"\u00dcber den Crawler"},{"location":"crawler/installation/","text":"Installation und Ausf\u00fchrung Ohne Docker Stellen Sie sicher, dass .NET 5.0 SDK auf Ihrem System installiert ist Klonen Sie das Repository Bauen Sie die Anwendung mit dotnet publish ./Crawler -c Release Wechseln Sie zum Ausgabeverzeichnis des Builds ./Crawler/bin/Release/net5.0/publish Folgen Sie dem Anleitungsschritt \"Konfiguration\" F\u00fchren Sie die Anwendung aus ./Crawler.exe Mit Docker Compose Bauen Klonen Sie das Repository F\u00fchren Sie folgenden Befehl im Root-Verzeichnis des Repositories aus, um das Docker-Image zu bauen: docker build . --tag crawler Ausf\u00fchren Erstellen Sie eine appsettings.json mit Ihren gew\u00fcnschten Einstellungswerten. F\u00fchren Sie den Docker-Container aus mit docker-run -v ./appsettings.json:/app/appsettings.json crawler Mounting Points Der Pfad /app/data/ muss zum Hostsystem persistiert werden, damit der Crawler tracken kann, welche Protokolle bereits indexiert wurden. Die appsettings.json Datei muss nach /app/appsettings.json gemounted werden, falls die Konfiguration via .json-Datei geschehen soll. Alternativ kann dieser Schritt weggelassen werden, wenn die Konfiguration via Umgebungsvariablen geschieht Konfiguration Die Konfiguration geschieht \u00fcber die in der Standard-Konfigurationsdatei bereitgestellen Parameter. \u00dcber den Einsellungen sind Kommentare zur Erl\u00e4uterung vorhanden. Es muss entweder die appsettings.json existieren oder es m\u00fcssen alle vom Standard abweichenden Einstellungen \u00fcber gleichnamige Umgebungsvariablen \u00fcbergeben werden. Umgebungsvariablen \u00fcberschreiben die Werte der appsettings.json. Wenn z.B. die Einstellung Interval \u00fcberschrieben werden soll mit einer Umgebungsvariable, dann muss die Umgungsvariable auch Interval hei\u00dfen. Name Standardwert Beschreibung Interval * * * * * Intervall als CRON-Expression, die bestimmt in welchem Intervall der Crawler die Seite des Bundestages \u00fcberpr\u00fcft. InitialDelay 0 Einmalige Verz\u00f6gerung des Anwendungsstarts in Sekunden. ChunkDelay 0 Verz\u00f6gerung zwischen den POST Anfragen an die Indexing-API in Sekunden. MaximumBatchSize 5 Maximale Anzahl der Reden die in einer POST Anfrage an die Indexing-API \u00fcbergeben werden. MongoConnectionString mongodb://0.0.0.0:8430 Verbindungsstring zur Mongo-DB Datenbank, in der der Crawler extrahierte Reden ablegen wird. MongoDatabase crawler Name der Datenbank. MongoCollection protocols Name der Collection. LocalDbConnectionString Data Source=data/local.db Verbindungsstring zur SQLite Datenbank, die der Crawler nutzt um abzuspeichern welche Dokumente bereits indexiert wurden. IndexingApiEndpoint http://0.0.0.0:8421/api Endpunkt des P2P Netzwerkes, an den der Crawler Reden zur Indexierung schickt. IndexingApiTimeout 300 Timeout der HTTP Anfrage der vorangehenden Einstellung.","title":"Installation"},{"location":"crawler/installation/#installation-und-ausfuhrung","text":"","title":"Installation und Ausf\u00fchrung"},{"location":"crawler/installation/#ohne-docker","text":"Stellen Sie sicher, dass .NET 5.0 SDK auf Ihrem System installiert ist Klonen Sie das Repository Bauen Sie die Anwendung mit dotnet publish ./Crawler -c Release Wechseln Sie zum Ausgabeverzeichnis des Builds ./Crawler/bin/Release/net5.0/publish Folgen Sie dem Anleitungsschritt \"Konfiguration\" F\u00fchren Sie die Anwendung aus ./Crawler.exe","title":"Ohne Docker"},{"location":"crawler/installation/#mit-docker-compose","text":"","title":"Mit Docker Compose"},{"location":"crawler/installation/#bauen","text":"Klonen Sie das Repository F\u00fchren Sie folgenden Befehl im Root-Verzeichnis des Repositories aus, um das Docker-Image zu bauen: docker build . --tag crawler","title":"Bauen"},{"location":"crawler/installation/#ausfuhren","text":"Erstellen Sie eine appsettings.json mit Ihren gew\u00fcnschten Einstellungswerten. F\u00fchren Sie den Docker-Container aus mit docker-run -v ./appsettings.json:/app/appsettings.json crawler","title":"Ausf\u00fchren"},{"location":"crawler/installation/#mounting-points","text":"Der Pfad /app/data/ muss zum Hostsystem persistiert werden, damit der Crawler tracken kann, welche Protokolle bereits indexiert wurden. Die appsettings.json Datei muss nach /app/appsettings.json gemounted werden, falls die Konfiguration via .json-Datei geschehen soll. Alternativ kann dieser Schritt weggelassen werden, wenn die Konfiguration via Umgebungsvariablen geschieht","title":"Mounting Points"},{"location":"crawler/installation/#konfiguration","text":"Die Konfiguration geschieht \u00fcber die in der Standard-Konfigurationsdatei bereitgestellen Parameter. \u00dcber den Einsellungen sind Kommentare zur Erl\u00e4uterung vorhanden. Es muss entweder die appsettings.json existieren oder es m\u00fcssen alle vom Standard abweichenden Einstellungen \u00fcber gleichnamige Umgebungsvariablen \u00fcbergeben werden. Umgebungsvariablen \u00fcberschreiben die Werte der appsettings.json. Wenn z.B. die Einstellung Interval \u00fcberschrieben werden soll mit einer Umgebungsvariable, dann muss die Umgungsvariable auch Interval hei\u00dfen. Name Standardwert Beschreibung Interval * * * * * Intervall als CRON-Expression, die bestimmt in welchem Intervall der Crawler die Seite des Bundestages \u00fcberpr\u00fcft. InitialDelay 0 Einmalige Verz\u00f6gerung des Anwendungsstarts in Sekunden. ChunkDelay 0 Verz\u00f6gerung zwischen den POST Anfragen an die Indexing-API in Sekunden. MaximumBatchSize 5 Maximale Anzahl der Reden die in einer POST Anfrage an die Indexing-API \u00fcbergeben werden. MongoConnectionString mongodb://0.0.0.0:8430 Verbindungsstring zur Mongo-DB Datenbank, in der der Crawler extrahierte Reden ablegen wird. MongoDatabase crawler Name der Datenbank. MongoCollection protocols Name der Collection. LocalDbConnectionString Data Source=data/local.db Verbindungsstring zur SQLite Datenbank, die der Crawler nutzt um abzuspeichern welche Dokumente bereits indexiert wurden. IndexingApiEndpoint http://0.0.0.0:8421/api Endpunkt des P2P Netzwerkes, an den der Crawler Reden zur Indexierung schickt. IndexingApiTimeout 300 Timeout der HTTP Anfrage der vorangehenden Einstellung.","title":"Konfiguration"},{"location":"design_decisions/about/","text":"Design decisions This section is dedicated to the major design decisions that were made within the duration of the project and the reasoning behind these decisions.","title":"About"},{"location":"design_decisions/about/#design-decisions","text":"This section is dedicated to the major design decisions that were made within the duration of the project and the reasoning behind these decisions.","title":"Design decisions"},{"location":"design_decisions/architecture_diagram/","text":"Architecture diagram This diagram is an overview of the overarching architecture we used for our project.","title":"Architecture Diagram"},{"location":"design_decisions/architecture_diagram/#architecture-diagram","text":"This diagram is an overview of the overarching architecture we used for our project.","title":"Architecture diagram"},{"location":"design_decisions/partition_by_keyword/","text":"Beispiel Partition By Keyword von zentraler Volltextsuche aus Drei Dokumente: d1, d2, d3 Vier Terme: t1, t2, t3, t4 Drei Peers: p1, p2, p3 Dokumente: d1 = {t1, t2, t3} d2 = {t4} d3 = {t1, t2} Hashen der Terme auf die Peers: T1 -> p1 T2 -> p2 T3 -> p3 T4 -> p1 Indexing Wenn ein Dokument neu indexiert werden soll, kann z.B. durch Hashing des Dokuments der verantwortliche Peer bestimmt werden, der das Dokument vorverarbeitet (tokenizing, stemming, indexing, \u2026) Alle gefundenen Terme werden gehashed und nach zust\u00e4ndigen Peers zusammengefasst Die Terme werden inklusive der Postinglisten als Batch (\u00fcber die P2P Logik) an den jeweils zust\u00e4ndigen Peer gesendet Der jeweils zust\u00e4ndige Peer f\u00fcgt die Terme mit Postinglisten in seinen eigenen (lokalen) Invertierten Index hinzu oder nimmt es in die bereits vorhandene Postingliste auf, falls der Term bereits bekannt ist. Beispiel: Invertierter Index auf den einzelnen Peers: P1 { t1 = [d1, d3] t4 = [d2] } P2 { t2 = [d1, d3] } P3 { t3 = [d1] } Der gesamte Index eines jeden Peers k\u00f6nnte nun noch auf den jeweiligen Vorg\u00e4nger repliziert werden. F\u00e4llt ein Peer unerwartet aus, kann der vorherige Peer als Fallback dienen: P1 { t1 = [d1, d3] t2 = [d1, d3] t4 = [d2] } P2 { t2 = [d1, d3] t3 = [d1] } P3 { t1 = [d1, d3] t3 = [d1] t4 = [d2] } Die Redundanz gleicht sich mit steigender Anzahl der Peers aus und k\u00f6nnte ggF. sogar auch auf den Nachfolger ausgeweitet werden. Retrieval Es wird ein Request gegen die Volltextsuche auf einem beliebigem Peer gestellt Das wird in unserem Fall immer der Peer sein, von dessen UI die Suche gestellt wurde Die Volltextsuche extrahiert die einzelnen Terme der Query und ruft diese \u00fcber die P2P Logik aus dem Distributed Inverted Index ab F\u00fcr den Fall, dass einer der gesuchten Terme auf Peer liegt, von dem die Anfrage ausgeht, sollten Optimierungen vorgenommen werden, so dass der Zugriff einem einfachen lokalen Zugriff gleicht, der aber trotzdem \u00fcber den Distributed Inverted Index abstrahiert wird. Sobald die Volltextsuche die Postinglisten erhalten hat, kann sie diese verarbeiten, das Ranking durchf\u00fchren und die sortierten Ergebnisse zur\u00fcck liefern. Hier kann \u00fcberlegt werden, ob die Postinglisten inkrementell zur\u00fcck gegeben werden, so dass die Volltextsuche schon arbeiten kann, w\u00e4hrend die P2P-Logik die restlichen Postinglisten noch sucht. Beispiel: Anfragen: A1 = \u201et1 AND t3\u201c A2 =\u201et3 AND t4\u201c A3 = \u201et2\u201c A1: Anfrage landet auf beliebigem Peer, dieser greift auf den Invertierten Index zu und baut das Ergebnis zusammen. F\u00e4llt der Peer f\u00fcr einer der Terme aus, wird \u00fcber den DHT (das P2P Framework) auf den Fallback Peer zur\u00fcckgegriffen. In beiden F\u00e4llen vollst\u00e4ndiges und zuverl\u00e4ssiges Ergebnis, auch wenn einer der Peers ausf\u00e4llt. A2: Gleiches Verhalten wie bei A1. Vollst\u00e4ndiges und zuverl\u00e4ssiges Ergebnis, auch wenn einer der Peers ausf\u00e4llt A3: Gleiches Verhalten wie bei A1. Vollst\u00e4ndiges und zuverl\u00e4ssiges Ergebnis, auch wenn einer der Peers ausf\u00e4llt Indexing und Retrieval nach Parteizugeh\u00f6rigkeit und Rednername Damit auch performant nach allen Reden einer Partei oder eines einzelnen Redners gesucht werden kann werden beim Indexing zwei Spezial-Tokens f\u00fcr Partei- und Rednername angelegt. Diese bekommen einen besonderen Prefix, damit sie von einfachen Termen unterschieden werden k\u00f6nnen. Beim indizieren einer Rede werden dann also jeweils zwei zus\u00e4tzliche Schl\u00fcssel im Distributed Inverted Index abgelegt, die beide das entsprechende Dokument beinhalten. Beispiel d1 = {t1, t2, t3} von Angela Merkel (CDU) Hashing: t1 -> p1 t2 -> p2 t3 -> p3 _speaker:angelamerkel -> p1 _affiliation:cdu -> p2 Der Prefix ist hier nur ein Beispiel und muss im Weiteren noch festgelegt werden Index: P1 { t1 = [d1] } P2 { t2 = [d1] } P3 { t3 = [d1] } Argumentation der Design-Entscheidung Nachteil gegen\u00fcber des Partition By Document Ansatzes ist, dass die Suche nur als gesamtes Netzwerk wirklich funktionsf\u00e4hig ist. Bei Partition By Document kann jeder Peer eine eigenst\u00e4ndige Volltextsuche f\u00fcr alle ihm zugeordneten Dokumente vornehmen. Vorteil hingegen ist, dass das Netzwerk nicht f\u00fcr jede einzelne Query geflutet (Broadcast) werden muss, sondern lediglich die f\u00fcr die entsprechenden Keywords der Query verantwortlichen Peers angefragt werden m\u00fcssen.","title":"Partition by Keyword"},{"location":"design_decisions/partition_by_keyword/#beispiel-partition-by-keyword-von-zentraler-volltextsuche-aus","text":"Drei Dokumente: d1, d2, d3 Vier Terme: t1, t2, t3, t4 Drei Peers: p1, p2, p3 Dokumente: d1 = {t1, t2, t3} d2 = {t4} d3 = {t1, t2} Hashen der Terme auf die Peers: T1 -> p1 T2 -> p2 T3 -> p3 T4 -> p1","title":"Beispiel Partition By Keyword von zentraler Volltextsuche aus"},{"location":"design_decisions/partition_by_keyword/#indexing","text":"Wenn ein Dokument neu indexiert werden soll, kann z.B. durch Hashing des Dokuments der verantwortliche Peer bestimmt werden, der das Dokument vorverarbeitet (tokenizing, stemming, indexing, \u2026) Alle gefundenen Terme werden gehashed und nach zust\u00e4ndigen Peers zusammengefasst Die Terme werden inklusive der Postinglisten als Batch (\u00fcber die P2P Logik) an den jeweils zust\u00e4ndigen Peer gesendet Der jeweils zust\u00e4ndige Peer f\u00fcgt die Terme mit Postinglisten in seinen eigenen (lokalen) Invertierten Index hinzu oder nimmt es in die bereits vorhandene Postingliste auf, falls der Term bereits bekannt ist.","title":"Indexing"},{"location":"design_decisions/partition_by_keyword/#beispiel","text":"Invertierter Index auf den einzelnen Peers: P1 { t1 = [d1, d3] t4 = [d2] } P2 { t2 = [d1, d3] } P3 { t3 = [d1] } Der gesamte Index eines jeden Peers k\u00f6nnte nun noch auf den jeweiligen Vorg\u00e4nger repliziert werden. F\u00e4llt ein Peer unerwartet aus, kann der vorherige Peer als Fallback dienen: P1 { t1 = [d1, d3] t2 = [d1, d3] t4 = [d2] } P2 { t2 = [d1, d3] t3 = [d1] } P3 { t1 = [d1, d3] t3 = [d1] t4 = [d2] } Die Redundanz gleicht sich mit steigender Anzahl der Peers aus und k\u00f6nnte ggF. sogar auch auf den Nachfolger ausgeweitet werden.","title":"Beispiel:"},{"location":"design_decisions/partition_by_keyword/#retrieval","text":"Es wird ein Request gegen die Volltextsuche auf einem beliebigem Peer gestellt Das wird in unserem Fall immer der Peer sein, von dessen UI die Suche gestellt wurde Die Volltextsuche extrahiert die einzelnen Terme der Query und ruft diese \u00fcber die P2P Logik aus dem Distributed Inverted Index ab F\u00fcr den Fall, dass einer der gesuchten Terme auf Peer liegt, von dem die Anfrage ausgeht, sollten Optimierungen vorgenommen werden, so dass der Zugriff einem einfachen lokalen Zugriff gleicht, der aber trotzdem \u00fcber den Distributed Inverted Index abstrahiert wird. Sobald die Volltextsuche die Postinglisten erhalten hat, kann sie diese verarbeiten, das Ranking durchf\u00fchren und die sortierten Ergebnisse zur\u00fcck liefern. Hier kann \u00fcberlegt werden, ob die Postinglisten inkrementell zur\u00fcck gegeben werden, so dass die Volltextsuche schon arbeiten kann, w\u00e4hrend die P2P-Logik die restlichen Postinglisten noch sucht.","title":"Retrieval"},{"location":"design_decisions/partition_by_keyword/#beispiel_1","text":"Anfragen: A1 = \u201et1 AND t3\u201c A2 =\u201et3 AND t4\u201c A3 = \u201et2\u201c A1: Anfrage landet auf beliebigem Peer, dieser greift auf den Invertierten Index zu und baut das Ergebnis zusammen. F\u00e4llt der Peer f\u00fcr einer der Terme aus, wird \u00fcber den DHT (das P2P Framework) auf den Fallback Peer zur\u00fcckgegriffen. In beiden F\u00e4llen vollst\u00e4ndiges und zuverl\u00e4ssiges Ergebnis, auch wenn einer der Peers ausf\u00e4llt. A2: Gleiches Verhalten wie bei A1. Vollst\u00e4ndiges und zuverl\u00e4ssiges Ergebnis, auch wenn einer der Peers ausf\u00e4llt A3: Gleiches Verhalten wie bei A1. Vollst\u00e4ndiges und zuverl\u00e4ssiges Ergebnis, auch wenn einer der Peers ausf\u00e4llt","title":"Beispiel:"},{"location":"design_decisions/partition_by_keyword/#indexing-und-retrieval-nach-parteizugehorigkeit-und-rednername","text":"Damit auch performant nach allen Reden einer Partei oder eines einzelnen Redners gesucht werden kann werden beim Indexing zwei Spezial-Tokens f\u00fcr Partei- und Rednername angelegt. Diese bekommen einen besonderen Prefix, damit sie von einfachen Termen unterschieden werden k\u00f6nnen. Beim indizieren einer Rede werden dann also jeweils zwei zus\u00e4tzliche Schl\u00fcssel im Distributed Inverted Index abgelegt, die beide das entsprechende Dokument beinhalten.","title":"Indexing und Retrieval nach Parteizugeh\u00f6rigkeit und Rednername"},{"location":"design_decisions/partition_by_keyword/#beispiel_2","text":"d1 = {t1, t2, t3} von Angela Merkel (CDU) Hashing: t1 -> p1 t2 -> p2 t3 -> p3 _speaker:angelamerkel -> p1 _affiliation:cdu -> p2 Der Prefix ist hier nur ein Beispiel und muss im Weiteren noch festgelegt werden Index: P1 { t1 = [d1] } P2 { t2 = [d1] } P3 { t3 = [d1] }","title":"Beispiel"},{"location":"design_decisions/partition_by_keyword/#argumentation-der-design-entscheidung","text":"Nachteil gegen\u00fcber des Partition By Document Ansatzes ist, dass die Suche nur als gesamtes Netzwerk wirklich funktionsf\u00e4hig ist. Bei Partition By Document kann jeder Peer eine eigenst\u00e4ndige Volltextsuche f\u00fcr alle ihm zugeordneten Dokumente vornehmen. Vorteil hingegen ist, dass das Netzwerk nicht f\u00fcr jede einzelne Query geflutet (Broadcast) werden muss, sondern lediglich die f\u00fcr die entsprechenden Keywords der Query verantwortlichen Peers angefragt werden m\u00fcssen.","title":"Argumentation der Design-Entscheidung"},{"location":"design_decisions/speech_handling_diagrams/","text":"Sequence diagrams about handling speeches The following two sequence diagrams describe our chosen process for indexing and retrieving speeches. Indexing speeches: Retrieving speeches:","title":"Speech Handling Diagrams"},{"location":"design_decisions/speech_handling_diagrams/#sequence-diagrams-about-handling-speeches","text":"The following two sequence diagrams describe our chosen process for indexing and retrieving speeches. Indexing speeches: Retrieving speeches:","title":"Sequence diagrams about handling speeches"},{"location":"fulltext-search/about/","text":"Bundestag Speech Search Simple search engine for querying speeches from the Bundestag .","title":"About"},{"location":"fulltext-search/about/#bundestag-speech-search","text":"Simple search engine for querying speeches from the Bundestag .","title":"Bundestag Speech Search"},{"location":"fulltext-search/get_started/","text":"Get started $ git clone https://github.com/htw-projekt-p2p-volltextsuche/fulltext-search $ cd fulltext-search $ sbt run Configure the App The application configuration can be specified in src/main/resources/application.conf in HOCON notation. It's also possible to override the application.conf by java system properties or environment variables. Environment variables need to be prefixed by CONFIG_FORCE_ except if there is an env-alias specified for the property. They will be evaluated in following order (starting from the highest priority): Environment variable: export CONFIG_FORCE_SERVER_HOST=\"0.0.0.0\" This actually doesn't work! - use env-alias if defined Java system property as argument: sbt '; set javaOptions += \"-Dserver.host=\"0.0.0.0\"\"; run' application.conf : server { host = 0.0.0.0 } Configuration properties identifier description env-alias default server.port HTTP port of the service HTTP_PORT 8421 server.host Host of the service SERVER_HOST 0.0.0.0 server.log-body Enables server logging of response bodies SERVER_LOG_BODY true index.storage Storage policy for the inverted index INDEX_STORAGE_POLICY local index.stop-words-location File name of the stopwords resource - stopwords_de.txt index.sample-speeches-location File name of the sample speeches resource - sample_speeches.json index.insert-sample-speeches Inserts sample speeches on startup when set - false index.distribution-interval Interval for scanning and distributing the cached index in ms INDEX_DISTRIBUTION_INTERVAL 120000 index.distribution-chunk-size Size of each concurrently processed chunk of the cached index INDEX_DISTRIBUTION_CHUNK_SIZE 100 index.insertion-ttl Amount of retries for the insertion of single index entry INDEX_INSERTION_TTL 5 search.cache-size Size of cache for search results SEARCH_CACHE_SIZE 5 peers.uri Entrypoint to the P2P network - http://localhost:8090/ peers.log-body Enables client logging of response bodies PEERS_LOG_BODY true peers.max-wait-queue-limit Max wait queue limit for requests to peers PEERS_MAX_WAIT_QUEUE_LIMIT 1024 Index Storage Policies The application can be started with three different storage policies. They work as follows: local Indexing and retrieval are both done locally in memory on the host machine. distributed Indexing and retrieval are handled by calling the P2P network directly. \u26a0\ufe0f Using this option, the index request is blocked until all entries are distributed to the P2P network. This can possibly take a long while. Therefore, an appropriate timeout should be set on the calling machine. lazy-distributed Indexing is done by first storing the index in a local cache and then distributing it on a background thread. The interval for scanning the cached index can be configured with the option index.distribution-interval Run tests $ sbt test","title":"Get Started"},{"location":"fulltext-search/get_started/#get-started","text":"$ git clone https://github.com/htw-projekt-p2p-volltextsuche/fulltext-search $ cd fulltext-search $ sbt run","title":"Get started"},{"location":"fulltext-search/get_started/#configure-the-app","text":"The application configuration can be specified in src/main/resources/application.conf in HOCON notation. It's also possible to override the application.conf by java system properties or environment variables. Environment variables need to be prefixed by CONFIG_FORCE_ except if there is an env-alias specified for the property. They will be evaluated in following order (starting from the highest priority): Environment variable: export CONFIG_FORCE_SERVER_HOST=\"0.0.0.0\" This actually doesn't work! - use env-alias if defined Java system property as argument: sbt '; set javaOptions += \"-Dserver.host=\"0.0.0.0\"\"; run' application.conf : server { host = 0.0.0.0 }","title":"Configure the App"},{"location":"fulltext-search/get_started/#configuration-properties","text":"identifier description env-alias default server.port HTTP port of the service HTTP_PORT 8421 server.host Host of the service SERVER_HOST 0.0.0.0 server.log-body Enables server logging of response bodies SERVER_LOG_BODY true index.storage Storage policy for the inverted index INDEX_STORAGE_POLICY local index.stop-words-location File name of the stopwords resource - stopwords_de.txt index.sample-speeches-location File name of the sample speeches resource - sample_speeches.json index.insert-sample-speeches Inserts sample speeches on startup when set - false index.distribution-interval Interval for scanning and distributing the cached index in ms INDEX_DISTRIBUTION_INTERVAL 120000 index.distribution-chunk-size Size of each concurrently processed chunk of the cached index INDEX_DISTRIBUTION_CHUNK_SIZE 100 index.insertion-ttl Amount of retries for the insertion of single index entry INDEX_INSERTION_TTL 5 search.cache-size Size of cache for search results SEARCH_CACHE_SIZE 5 peers.uri Entrypoint to the P2P network - http://localhost:8090/ peers.log-body Enables client logging of response bodies PEERS_LOG_BODY true peers.max-wait-queue-limit Max wait queue limit for requests to peers PEERS_MAX_WAIT_QUEUE_LIMIT 1024","title":"Configuration properties"},{"location":"fulltext-search/get_started/#index-storage-policies","text":"The application can be started with three different storage policies. They work as follows: local Indexing and retrieval are both done locally in memory on the host machine. distributed Indexing and retrieval are handled by calling the P2P network directly. \u26a0\ufe0f Using this option, the index request is blocked until all entries are distributed to the P2P network. This can possibly take a long while. Therefore, an appropriate timeout should be set on the calling machine. lazy-distributed Indexing is done by first storing the index in a local cache and then distributing it on a background thread. The interval for scanning the cached index can be configured with the option index.distribution-interval","title":"Index Storage Policies"},{"location":"fulltext-search/get_started/#run-tests","text":"$ sbt test","title":"Run tests"},{"location":"fulltext-search/retrieve_search_results/","text":"Retrieve Search Results \ud83d\udcc1 To the API-Doc's Simple Queries Only searches with at least one term in the query fields are valid. All the other fields are optional. To limit the maximum number of results search.max_results can be set to any positive integer. The simplest possible search request has following form: json { \"search\": { \"query\": { \"terms\": \"your query here...\" } } } In the above example all the terms specified in terms will be combined with AND . To combine the terms with different boolean operators the search you can extend the search with arbitrary additional terms. json { \"search\": { \"query\": { \"terms\": \"find this ...\", \"additions\": [ { \"connector\": \"or\", \"terms\": \"... or that ...\" }, { \"connector\": \"and_not\", \"terms\": \"... but not that\" } ] } } } Evaluation order of boolean operators First all terms fields are evaluated with AND in isolation. The results will then be combined by the specified connector and evaluated in the following order: AND_NOT AND OR Filtered Queries Up until now the queries can be filtered by speaker or affiliation . If several filters with same criteria are specified they're combined by OR , while the entire set resulting from all filters of same type will by combined by AND with the actually specified query results. json { \"search\": { \"query\": { \"terms\": \"some search\" }, \"filter\": [ { \"criteria\": \"affiliation\", \"value\": \"SPD\" }, { \"criteria\": \"affiliation\", \"value\": \"Die Linke\" }, { \"criteria\": \"speaker\", \"value\": \"Peter Lustig\" } ] } }","title":"Retrieve search results"},{"location":"fulltext-search/retrieve_search_results/#retrieve-search-results","text":"\ud83d\udcc1 To the API-Doc's","title":"Retrieve Search Results"},{"location":"fulltext-search/retrieve_search_results/#simple-queries","text":"Only searches with at least one term in the query fields are valid. All the other fields are optional. To limit the maximum number of results search.max_results can be set to any positive integer. The simplest possible search request has following form: json { \"search\": { \"query\": { \"terms\": \"your query here...\" } } } In the above example all the terms specified in terms will be combined with AND . To combine the terms with different boolean operators the search you can extend the search with arbitrary additional terms. json { \"search\": { \"query\": { \"terms\": \"find this ...\", \"additions\": [ { \"connector\": \"or\", \"terms\": \"... or that ...\" }, { \"connector\": \"and_not\", \"terms\": \"... but not that\" } ] } } }","title":"Simple Queries"},{"location":"fulltext-search/retrieve_search_results/#evaluation-order-of-boolean-operators","text":"First all terms fields are evaluated with AND in isolation. The results will then be combined by the specified connector and evaluated in the following order: AND_NOT AND OR","title":"Evaluation order of boolean operators"},{"location":"fulltext-search/retrieve_search_results/#filtered-queries","text":"Up until now the queries can be filtered by speaker or affiliation . If several filters with same criteria are specified they're combined by OR , while the entire set resulting from all filters of same type will by combined by AND with the actually specified query results. json { \"search\": { \"query\": { \"terms\": \"some search\" }, \"filter\": [ { \"criteria\": \"affiliation\", \"value\": \"SPD\" }, { \"criteria\": \"affiliation\", \"value\": \"Die Linke\" }, { \"criteria\": \"speaker\", \"value\": \"Peter Lustig\" } ] } }","title":"Filtered Queries"},{"location":"home/","text":"Peer 2 Peer Fulltext search This is a project created for the Hochschule f\u00fcr Technik und Wirtschaft in Berlin. The participants are: Boris Caspary Emma Calewaert Jonathan Neidel Joscha Seelig Leon Enzenberger Ryan Torzynski Simon Breiter Stefan Sadewasser The repository for the project can be found here","title":"Credits"},{"location":"home/#peer-2-peer-fulltext-search","text":"This is a project created for the Hochschule f\u00fcr Technik und Wirtschaft in Berlin. The participants are: Boris Caspary Emma Calewaert Jonathan Neidel Joscha Seelig Leon Enzenberger Ryan Torzynski Simon Breiter Stefan Sadewasser The repository for the project can be found here","title":"Peer 2 Peer Fulltext search"},{"location":"home/basic_concepts/","text":"Basic concepts In this project, we've combined two basic concepts into an application: the peer-2-peer network and the fulltext search. In order to explain more about our project, a broad definition of these two concepts must be established. On one hand, we have the peer-2-peer network. This is a network type where, in contrast to the classic client-server model, each participating node has equal rights. On the other hand, there's the full text search. This is a type of purely syntactical search, where the goal is to find given words in a large set of documents. Often this process if divided into two phases: The indexing phase - where documents are collected, prepared and indexed - and the search phase - where requests are received, corresponding documents are gathered, ranked and displayed to the user.","title":"Basic concepts"},{"location":"home/basic_concepts/#basic-concepts","text":"In this project, we've combined two basic concepts into an application: the peer-2-peer network and the fulltext search. In order to explain more about our project, a broad definition of these two concepts must be established. On one hand, we have the peer-2-peer network. This is a network type where, in contrast to the classic client-server model, each participating node has equal rights. On the other hand, there's the full text search. This is a type of purely syntactical search, where the goal is to find given words in a large set of documents. Often this process if divided into two phases: The indexing phase - where documents are collected, prepared and indexed - and the search phase - where requests are received, corresponding documents are gathered, ranked and displayed to the user.","title":"Basic concepts"},{"location":"home/subject/","text":"Subject The subject for our fulltext search are the speeches of the Bundestag . This set of data was chosen due to its Open Data nature combined with the size of the dataset and the fact that these protocols are recorded live into an XML formatted document. The XML format should mean, that these files are easier to parse, but this was not always the case. There's a clear distinction between the 19th legistlative period and the 18th and earlier periods. <?xml version=\"1.0\" encoding=\"utf-8\" ?> <?xml-stylesheet href=\"dbtplenarprotokoll.css\" type=\"text/css\" charset=\"UTF-8\"?> <!DOCTYPE dbtplenarprotokoll SYSTEM \"dbtplenarprotokoll.dtd\"> <dbtplenarprotokoll vertrieb=\"Bundesanzeiger Verlagsgesellschaft mbH, Postfach 1 0 05 34, 50445 K\u00f6ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de\" herstellung=\"H. Heenemann GmbH Co. KG, Buch- und Offsetdruckerei, Bessemerstra\u00dfe 83\u201391, 12103 Berlin, www.heenemann-druck.de\" sitzung-ort=\"Berlin\" herausgeber=\"Deutscher Bundestag\" issn=\"0722-7980\" wahlperiode=\"19\" sitzung-nr=\"237\" sitzung-datum=\"25.06.2021\" sitzung-start-uhrzeit=\"9:00\" sitzung-ende-uhrzeit=\"18:16\" sitzung-naechste-datum=\"07.09.2021\" start-seitennr=\"30883\"> <vorspann> <kopfdaten> <plenarprotokoll-nummer>Plenarprotokoll <wahlperiode>19</wahlperiode>/<sitzungsnr>237</sitzungsnr> </plenarprotokoll-nummer> <herausgeber>Deutscher Bundestag</herausgeber> <berichtart>Stenografischer Bericht</berichtart> <sitzungstitel> <sitzungsnr>237</sitzungsnr>. Sitzung</sitzungstitel> <veranstaltungsdaten> <ort>Berlin</ort>, <datum date=\"25.06.2021\">Freitag, den 25. Juni 2021</datum> </veranstaltungsdaten> </kopfdaten> <inhaltsverzeichnis> <ivz-titel>Inhalt:</ivz-titel> <ivz-eintrag> <ivz-eintrag-inhalt>Absetzung des Zusatzpunktes 21</ivz-eintrag-inhalt> <a href=\"S30883\" typ=\"druckseitennummer\"> <seite>30883</seite> <seitenbereich>A</seitenbereich> </a> This first excerpt is an example from the 19th period. The document follows the XML structure well and provides good groundwork to allow easy parsing. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <DOKUMENT> <WAHLPERIODE>18</WAHLPERIODE> <DOKUMENTART>PLENARPROTOKOLL</DOKUMENTART> <NR>18/179</NR> <DATUM>23.06.2016</DATUM> <TITEL>Plenarprotokoll vom 23.06.2016</TITEL> <TEXT>Plenarprotokoll 18/179 Deutscher Bundestag Stenografischer Bericht 179. Sitzung Berlin, Donnerstag, den 23. Juni 2016 Inhalt: Wahl der Abgeordneten Nina Warken als or- dentliches Mitglied des Gemeinsamen Aus\u00ad schusses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17575 A Wahl des Abgeordneten Steffen Bilger als ordentliches Mitglied des Vermittlungsaus\u00ad schusses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17575 B Erweiterung und Abwicklung der Tagesord- nung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17575 B Absetzung der Tagesordnungspunkte 14, 15 b und 25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17576 D Begr\u00fc\u00dfung des Botschafters der Republik Polen, Herrn Jerzy Jozef Marganski . . . . . . 17613 C This second excerpt is an example from the 18th period. Without the few XML tags at the start of the document, it would be impossible to tell that this is indeed an XML file and not a plain text file. This made these documents quite a lot more difficult to parse. For more information about these problems and their solutions, please find the documentations about these respective components.","title":"Subject"},{"location":"home/subject/#subject","text":"The subject for our fulltext search are the speeches of the Bundestag . This set of data was chosen due to its Open Data nature combined with the size of the dataset and the fact that these protocols are recorded live into an XML formatted document. The XML format should mean, that these files are easier to parse, but this was not always the case. There's a clear distinction between the 19th legistlative period and the 18th and earlier periods. <?xml version=\"1.0\" encoding=\"utf-8\" ?> <?xml-stylesheet href=\"dbtplenarprotokoll.css\" type=\"text/css\" charset=\"UTF-8\"?> <!DOCTYPE dbtplenarprotokoll SYSTEM \"dbtplenarprotokoll.dtd\"> <dbtplenarprotokoll vertrieb=\"Bundesanzeiger Verlagsgesellschaft mbH, Postfach 1 0 05 34, 50445 K\u00f6ln, Telefon (02 21) 97 66 83 40, Fax (02 21) 97 66 83 44, www.betrifft-gesetze.de\" herstellung=\"H. Heenemann GmbH Co. KG, Buch- und Offsetdruckerei, Bessemerstra\u00dfe 83\u201391, 12103 Berlin, www.heenemann-druck.de\" sitzung-ort=\"Berlin\" herausgeber=\"Deutscher Bundestag\" issn=\"0722-7980\" wahlperiode=\"19\" sitzung-nr=\"237\" sitzung-datum=\"25.06.2021\" sitzung-start-uhrzeit=\"9:00\" sitzung-ende-uhrzeit=\"18:16\" sitzung-naechste-datum=\"07.09.2021\" start-seitennr=\"30883\"> <vorspann> <kopfdaten> <plenarprotokoll-nummer>Plenarprotokoll <wahlperiode>19</wahlperiode>/<sitzungsnr>237</sitzungsnr> </plenarprotokoll-nummer> <herausgeber>Deutscher Bundestag</herausgeber> <berichtart>Stenografischer Bericht</berichtart> <sitzungstitel> <sitzungsnr>237</sitzungsnr>. Sitzung</sitzungstitel> <veranstaltungsdaten> <ort>Berlin</ort>, <datum date=\"25.06.2021\">Freitag, den 25. Juni 2021</datum> </veranstaltungsdaten> </kopfdaten> <inhaltsverzeichnis> <ivz-titel>Inhalt:</ivz-titel> <ivz-eintrag> <ivz-eintrag-inhalt>Absetzung des Zusatzpunktes 21</ivz-eintrag-inhalt> <a href=\"S30883\" typ=\"druckseitennummer\"> <seite>30883</seite> <seitenbereich>A</seitenbereich> </a> This first excerpt is an example from the 19th period. The document follows the XML structure well and provides good groundwork to allow easy parsing. <?xml version=\"1.0\" encoding=\"UTF-8\"?> <DOKUMENT> <WAHLPERIODE>18</WAHLPERIODE> <DOKUMENTART>PLENARPROTOKOLL</DOKUMENTART> <NR>18/179</NR> <DATUM>23.06.2016</DATUM> <TITEL>Plenarprotokoll vom 23.06.2016</TITEL> <TEXT>Plenarprotokoll 18/179 Deutscher Bundestag Stenografischer Bericht 179. Sitzung Berlin, Donnerstag, den 23. Juni 2016 Inhalt: Wahl der Abgeordneten Nina Warken als or- dentliches Mitglied des Gemeinsamen Aus\u00ad schusses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17575 A Wahl des Abgeordneten Steffen Bilger als ordentliches Mitglied des Vermittlungsaus\u00ad schusses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17575 B Erweiterung und Abwicklung der Tagesord- nung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17575 B Absetzung der Tagesordnungspunkte 14, 15 b und 25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17576 D Begr\u00fc\u00dfung des Botschafters der Republik Polen, Herrn Jerzy Jozef Marganski . . . . . . 17613 C This second excerpt is an example from the 18th period. Without the few XML tags at the start of the document, it would be impossible to tell that this is indeed an XML file and not a plain text file. This made these documents quite a lot more difficult to parse. For more information about these problems and their solutions, please find the documentations about these respective components.","title":"Subject"},{"location":"home/work_division/","text":"Work division During our work on the project, our group naturally tended towards a division of the components into working groups. We had two major groups: The text processing group (crawler, extraction 18, extraction 19) and the fulltext-search group (P2P-DHT and fulltext-search). Aside from these groups, we also had OPS and the UI, which stood more separately on their own.","title":"Work division"},{"location":"home/work_division/#work-division","text":"During our work on the project, our group naturally tended towards a division of the components into working groups. We had two major groups: The text processing group (crawler, extraction 18, extraction 19) and the fulltext-search group (P2P-DHT and fulltext-search). Aside from these groups, we also had OPS and the UI, which stood more separately on their own.","title":"Work division"},{"location":"ops/about/","text":"Description short The OPS repository contains all configuration files and scripts used to deploy peers for the htw-projekt-p2p-volltextsuche. Description long The peer to peer network consists of nodes with equal functionality. The nodes all have an user-interface delivered via http, a service for searching for terms and p2p-distribution system for managing the inverted index of the search service. From here on such a node is called a \"peer\". There is a unique node which additionally to the functionality mentioned above, also hosts a central db holding all the speeches in json format as well as a crawler filling it with speeches. From here on this node is called the \"data\".","title":"About"},{"location":"ops/about/#description-short","text":"The OPS repository contains all configuration files and scripts used to deploy peers for the htw-projekt-p2p-volltextsuche.","title":"Description short"},{"location":"ops/about/#description-long","text":"The peer to peer network consists of nodes with equal functionality. The nodes all have an user-interface delivered via http, a service for searching for terms and p2p-distribution system for managing the inverted index of the search service. From here on such a node is called a \"peer\". There is a unique node which additionally to the functionality mentioned above, also hosts a central db holding all the speeches in json format as well as a crawler filling it with speeches. From here on this node is called the \"data\".","title":"Description long"},{"location":"ops/challenges/","text":"Challenges This project was originally intended to run with kubernetes. Due to limited server resources we changed course to use docker compose instead. Kubernetes was more likely to consume storage by writing to logs that aren't directly associated with kubernetes and are not removed when kubernetes data is cleared. This logging issue was first discovered after the switch to a docker compose based configuration. Due to the late integration phase of the project, there wasn't enough time to react adequately to this requirements change. This led to a time-consuming administration job because instances of services first need to be stopped, their images deleted and then new pulled instead of just pulling and replacing a running service. Furthermore logs needed to be limited to a small size which made debugging an interactive job because missed error logs were overwriten not even a minute later.","title":"Challenges"},{"location":"ops/challenges/#challenges","text":"This project was originally intended to run with kubernetes. Due to limited server resources we changed course to use docker compose instead. Kubernetes was more likely to consume storage by writing to logs that aren't directly associated with kubernetes and are not removed when kubernetes data is cleared. This logging issue was first discovered after the switch to a docker compose based configuration. Due to the late integration phase of the project, there wasn't enough time to react adequately to this requirements change. This led to a time-consuming administration job because instances of services first need to be stopped, their images deleted and then new pulled instead of just pulling and replacing a running service. Furthermore logs needed to be limited to a small size which made debugging an interactive job because missed error logs were overwriten not even a minute later.","title":"Challenges"},{"location":"ops/setup/","text":"Setup In order to setup a network of peers you need to setup one \"data\" node as well as as many peers you desire. If you don't need the scaling capability, you can just setup one data node as well. Development 1. Setup your firewall to allow communication through these ports: 22 (ssh) 80 (http) 8080 (alternate http port) 8421 (fulltext-search) 8090, 8070 (p2p-network) 8430 (mongodb) 8081 (ui-backend) 2. Install docker: https://docs.docker.com/get-docker/ 3. Install docker-compose: https://docs.docker.com/compose/install/ 4. clone this repository 5. go into ops/data/ 6. create a .env file with the following content MONGO_INITDB_ROOT_USERNAME=<[choose one]> MONGO_INITDB_ROOT_USERNAME=<[choose one]> DATA_HOST=<[the ip of your pc]> INDEX_STORAGE_POLICY=local UI_PORT=80 8. start the node you can start it with docker-compose up to see the complete log in the terminal. you can start it with docker-compose up -d if you want to run it as a deamon. 9. Stop the nodes again with docker-compose down if you are done. Production The first four steps are documented for transparency reasons. You can skip them by cloning this repository and executing install.sh The same goes for a testing-environment on which you don't need to setup the firewall and may already have installed docker (possible with root permissions). Setup without scripts. 1. Setup your firewall to allow communication through olny these ports: 22 (ssh) 80 (http) 8080 (alternate http port) 8421 (fulltext-search) 8090, 8070 (p2p-network) 8430 (mongodb) 8081 (ui-backend) Route port 80 to port 8080 to enable rootless access of the docker-container port 2. install docker rootless: https://docs.docker.com/engine/security/rootless/ 3. install docker-compose: https://docs.docker.com/compose/install/ 4. clone this repository 5. go into the folder representing this repository 6. create a .env file in the folder representing the type of node you want to deploy (peer or data) with the following values MONGO_INITDB_ROOT_USERNAME=<[for data choose one/for peer use the name of data]> MONGO_INITDB_ROOT_USERNAME=<[for data choose one/for peer use the password of data]> DATA_HOST=<[the ip of the server running the data node]> INDEX_STORAGE_POLICY=<[local, distributed or lazy-distributed]> PEER_LIST=<[see step 10 or leave blank for a single node setup]> UI_PORT=8080 Read more about the index storage policies 7. go into the folder representing the type of node you want to deploy (peer or data) 8. start the nodes you can start them with docker-compose up to see the complete log in the terminal. you can start them with docker-compose up -d if you want to run it as a deamon. 9. Stop the nodes again with docker-compose down after seeing the ascii-art \"https\"-logo. 10. Setup the PEER_LIST (after running all instances at least once)(only necessary for multi-node setups) copy the output of all the p2pframework containers signaling the \"own multiaddr:\" into the \"PEER_LIST\" var of every node. They should only be sepereated by a comma. See replace the \"0.0.0.0\"-part of the adresse with the corresponding ip of the node 11. Start the nodes again with docker-compose up .","title":"Setup"},{"location":"ops/setup/#setup","text":"In order to setup a network of peers you need to setup one \"data\" node as well as as many peers you desire. If you don't need the scaling capability, you can just setup one data node as well.","title":"Setup"},{"location":"ops/setup/#development","text":"","title":"Development"},{"location":"ops/setup/#1-setup-your-firewall-to-allow-communication-through-these-ports","text":"22 (ssh) 80 (http) 8080 (alternate http port) 8421 (fulltext-search) 8090, 8070 (p2p-network) 8430 (mongodb) 8081 (ui-backend)","title":"1. Setup your firewall to allow communication through these ports:"},{"location":"ops/setup/#2-install-docker-httpsdocsdockercomget-docker","text":"","title":"2. Install docker: https://docs.docker.com/get-docker/"},{"location":"ops/setup/#3-install-docker-compose-httpsdocsdockercomcomposeinstall","text":"","title":"3. Install docker-compose: https://docs.docker.com/compose/install/"},{"location":"ops/setup/#4-clone-this-repository","text":"","title":"4. clone this repository"},{"location":"ops/setup/#5-go-into-opsdata","text":"","title":"5. go into ops/data/"},{"location":"ops/setup/#6-create-a-env-file-with-the-following-content","text":"MONGO_INITDB_ROOT_USERNAME=<[choose one]> MONGO_INITDB_ROOT_USERNAME=<[choose one]> DATA_HOST=<[the ip of your pc]> INDEX_STORAGE_POLICY=local UI_PORT=80","title":"6. create a .env file with the following content"},{"location":"ops/setup/#8-start-the-node","text":"you can start it with docker-compose up to see the complete log in the terminal. you can start it with docker-compose up -d if you want to run it as a deamon.","title":"8. start the node"},{"location":"ops/setup/#9-stop-the-nodes-again-with-docker-compose-down-if-you-are-done","text":"","title":"9. Stop the nodes again with docker-compose down if you are done."},{"location":"ops/setup/#production","text":"The first four steps are documented for transparency reasons. You can skip them by cloning this repository and executing install.sh The same goes for a testing-environment on which you don't need to setup the firewall and may already have installed docker (possible with root permissions). Setup without scripts.","title":"Production"},{"location":"ops/setup/#1-setup-your-firewall-to-allow-communication-through-olny-these-ports","text":"22 (ssh) 80 (http) 8080 (alternate http port) 8421 (fulltext-search) 8090, 8070 (p2p-network) 8430 (mongodb) 8081 (ui-backend) Route port 80 to port 8080 to enable rootless access of the docker-container port","title":"1. Setup your firewall to allow communication through olny these ports:"},{"location":"ops/setup/#2-install-docker-rootless-httpsdocsdockercomenginesecurityrootless","text":"","title":"2. install docker rootless: https://docs.docker.com/engine/security/rootless/"},{"location":"ops/setup/#3-install-docker-compose-httpsdocsdockercomcomposeinstall_1","text":"","title":"3. install docker-compose: https://docs.docker.com/compose/install/"},{"location":"ops/setup/#4-clone-this-repository_1","text":"","title":"4. clone this repository"},{"location":"ops/setup/#5-go-into-the-folder-representing-this-repository","text":"","title":"5. go into the folder representing this repository"},{"location":"ops/setup/#6-create-a-env-file-in-the-folder-representing-the-type-of-node-you-want-to-deploy-peer-or-data-with-the-following-values","text":"MONGO_INITDB_ROOT_USERNAME=<[for data choose one/for peer use the name of data]> MONGO_INITDB_ROOT_USERNAME=<[for data choose one/for peer use the password of data]> DATA_HOST=<[the ip of the server running the data node]> INDEX_STORAGE_POLICY=<[local, distributed or lazy-distributed]> PEER_LIST=<[see step 10 or leave blank for a single node setup]> UI_PORT=8080 Read more about the index storage policies","title":"6. create a .env file in the folder representing the type of node you want to deploy (peer or data) with the following values"},{"location":"ops/setup/#7-go-into-the-folder-representing-the-type-of-node-you-want-to-deploy-peer-or-data","text":"","title":"7. go into the folder representing the type of node you want to deploy (peer or data)"},{"location":"ops/setup/#8-start-the-nodes","text":"you can start them with docker-compose up to see the complete log in the terminal. you can start them with docker-compose up -d if you want to run it as a deamon.","title":"8. start the nodes"},{"location":"ops/setup/#9-stop-the-nodes-again-with-docker-compose-down-after-seeing-the-ascii-art-https-logo","text":"","title":"9. Stop the nodes again with docker-compose down after seeing the ascii-art \"https\"-logo."},{"location":"ops/setup/#10-setup-the-peer_list-after-running-all-instances-at-least-onceonly-necessary-for-multi-node-setups","text":"copy the output of all the p2pframework containers signaling the \"own multiaddr:\" into the \"PEER_LIST\" var of every node. They should only be sepereated by a comma. See replace the \"0.0.0.0\"-part of the adresse with the corresponding ip of the node","title":"10. Setup the PEER_LIST (after running all instances at least once)(only necessary for multi-node setups)"},{"location":"ops/setup/#11-start-the-nodes-again-with-docker-compose-up","text":"","title":"11. Start the nodes again with docker-compose up."},{"location":"outlook/about/","text":"Outlook This section is dedicated to known imperfections of the project and possible future improvements.","title":"About"},{"location":"outlook/about/#outlook","text":"This section is dedicated to known imperfections of the project and possible future improvements.","title":"Outlook"},{"location":"outlook/future_optimizations/","text":"Leistungsoptimierungen des Anfrage- und Indexierungsprozess Bei der Integration der einzelnen Sub-Systeme zum Ende des Projektes, ist klar geworden, dass das Gesamtsystem vor allem beim Indexieren kritische Performance Defizite aufweist. Das Hauptproblem - Bottleneck: Netwerk Das Indexieren einer einzelnen Rede \u00fcber das P2P-Netzwerk ben\u00f6tigte fast eine halbe Stunde. Damit ist uns der vorher erwartete Overhead der hohen Netzwerklast sehr direkt klar geworden und wir haben uns im Projekt gemeinsam dazu entschlossen, Optimierungen vorzunehmen, um den Indexierungsprozess in einer vertretbaren Zeit durchf\u00fchren zu k\u00f6nnen. Zum Vergleich handelte es sich bei der lokalen Ausf\u00fchrung des gleichen Prozesses (also ohne Netzwerk-Overhead) lediglich um Millisekunden. Durch eine Code-Analyse konnten zwei wesentliche Ursachen der Problematik ausgemacht werden. 1. Die Requests von der Volltextsuche zum P2P-Netwerk wurden sequentiell abgearbeitet. * Hier konnten wir erfolgreich optimieren 2. Das P2P-Netzwerk hat, entgegen dem urspr\u00fcnglichen Plan, keine Zusammenf\u00fchrung aller auf einen Peer hinauslaufenden Requests angeboten. * Hier werden grundlegende, architektonische \u00c4nderungen ben\u00f6tigt, die in der \u00fcbrigen Zeit nicht zu schaffen waren L\u00f6sungsans\u00e4tze Paralleles Senden der Requests aus der Volltextsuche Der erste Versuch des Parallelisierens der Requests hat grunds\u00e4tzlich funktioniert, aber zwei weitere Probleme hervogerufen: * Aus der Volltextsuche wurden so viele Requests in so kurzer Zeit gesendet, dass das P2P-Netwerk nach kurzer Zeit \u00fcberlastet war. * Die Fehlerbehandlung innerhalb der Volltextsuche gestaltete sich als wesentlich komplexer gegen\u00fcber der sequentiellen Verarbeitung. Der folgende Ansatz, um diese Probleme in den Griff zu kriegen, war die Implementierung eines Load-Balancers, mit dem versucht wurde das Leistungs-Limit des P2P-Netzwerks auszunutzen, ohne dieses zu \u00fcberlasten und Fehler zu provozieren. Mit diesem Ansatz war es weiterhin sehr schwer, die Fehler anst\u00e4ndig zu behandeln und auch das Finden eines passenden Request-Limits gestaltete sich schwierig. Wesentlich erfolgreicher waren wir mit der Umsetzung der n\u00e4chsten Idee. Diese beruhte darauf, die Indexierung vorerst lokal im Hauptspeicher vorzunehmen und den resultierenden lokal gecachten Index anschlie\u00dfend \u00fcber einen regelm\u00e4\u00dfigen Batch-Job im Hintergrund ins P2P-Netz zu \u00fcbertragen. Der Batch-Job wurde zeitgesteuert angesto\u00dfen und auf separaten Threads ausgef\u00fchrt. Bei jedem Lauf wurde nur eine bestimmte Menge an zu \u00fcbertragenden Postings aus dem lokalen Index gelesen, um die einzelnen Sendedurchl\u00e4ufe m\u00f6glichst kurz zu halten. Sowohl das Sendeintervall, als auch die Menge eines zu sendenden Datenblocks wurde konfigurierbar gestaltet, um beim weiteren Experimentieren problemlos Anpassungen vornehmen zu k\u00f6nnen und die Werte ggF. sogar an die genutzte Umgebung anzupassen. Auch die Fehlerbehandlung lie\u00df sich mit diesem Ansatz leichter angehen. Alle Fehler die beim Senden der Requests vorgekommen sind, wurden entweder als FATAL_ERROR oder als RECOVERABLE_ERROR eingestuft. Die Requests, die fatale Fehler verursacht haben, wurden verworfen, um die Sende-Queue nicht weiter zu blockieren. Die Requests, die nicht fatale Fehler verursachten, wurden mit einem TTL versehen und so lange zur\u00fcck in den lokalen Cache geschrieben, bis deren TTL abgelaufen ist und auch diese Verworfen wurden. Mit diesem Ansatz ist es uns gelungen die Laufzeit der Indexierung einer einzelnen, durchschnittlichen Rede von einer knappen halben Stunde auf unter 3 Minuten zu bringen. Dieses Ergebnis ist immer noch nicht befriedigend, doch f\u00fcr einen einzelnen Optimierungsversuch ein gro\u00dfer Erfolg. Minimieren der Netzwerklast durch Aggregation der Requests pro Peer Uns war klar, um weitere Leistungsverbesserungen zu erreichen m\u00fcssen wir die Anzahl der Requests minimieren, um das Netzwerk zu entlasten. F\u00fcr dieses Problem war die theoretische L\u00f6sung bereits gegeben, denn sie entspricht dem, was wir urspr\u00fcnglich f\u00fcr das P2P-Netwerk geplant haben. Anstatt f\u00fcr jedes einzelne Posting einen eigenen Request zu senden, m\u00fcssten wir den Hashwert des jeweiligen Postings errechnen und alle Postings, die gemeinsam auf einem Peer gespeichert werden sollen, in einem einzelnen Request zusammenfassen. Die Umsetzung dieses Ansatzes verlangt, tief in die Logik des P2P-Frameworks einzugreifen. Die von uns genutzte Bibliothek f\u00fcr die Implementierung des P2P-Frameworks bot diese M\u00f6glichkeit leider nicht nativ an. Das Austauschen dieser Bibliothek h\u00e4tte zu dem Zeitpunkt zu viel Zeit gekostet und das Umschreiben der Bibliothek auf eigene Faust birgte zu viele Risiken. Wir haben uns dann gemeinsam dazu entschlossen einen anderen Weg zu gehen. Weitere weniger kritische Optimierungen Im Laufe der Entwicklung haben wir einige weitere Optimierungen vorgenommen, wenn immer es angemessen schien. Grunds\u00e4tzlich ist klar geworden, dass in dem von uns gew\u00e4hlten Distibutionsmodell f\u00fcr den Invertierten Index, vorallem die Indexierungsphase Leistungsdefizite aufweist. Die Anfragephase hat wie erwartet wesentlich bessere Performance aufweisen k\u00f6nnen. Dennoch ergab sich auch f\u00fcr die Anfragephase Optimierungspotential: z.B. haben wir unter anderem in der Volltextsuche ein Caching der Suchanfragen implementiert. Wenn immer eine zuvor bereits gestellte Suchanfrage in kurzer Zeit erneut gestellt wurde, hat das System keine vollst\u00e4ndig neue Volltextsuche durchgef\u00fchrt, sondern die gecachte Antwort aus dem letzten Aufruf wiederverwendet. Dieses war vorallem f\u00fcr die Paginierung wichtig, die zwar im UI nicht implementiert wurde, doch in der Volltextsuche bereits voll funktionsf\u00e4hig war. Dieses Caching lie\u00dfe sich noch weiter verbessern, in dem ganze Postinglisten im Hauptspeicher vorgehalten werden w\u00fcrden, um diese auch f\u00fcr vollkommen neue Requests und sogar unabh\u00e4ngig vom aufrufenden Client nutzen zu k\u00f6nnen. Fazit Abschlie\u00dfend l\u00e4sst sich sagen, dass wir mit dem Gesamtergebnis des Projektes und den Erfolgen beim Optimieren sehr zufrieden sind. Die Problemstellung eine Volltextsuche auf Basis eines P2P-Netzwerks zu implementieren birgt viele versteckte Risiken. Zu Beginn des Projektes war in der gesamten Gruppe das Vorwissen eher gering ausgepr\u00e4gt. Wir sind froh, ein funktionierendes Gesamtsystem mit akzeptabler Leisung umgesetzt zu haben und als gesamte Gruppe tiefe Einblicke in die Thematik erlangt zu haben und gro\u00dfe Lernerfolge feiern zu k\u00f6nnen.","title":"Optimizations"},{"location":"outlook/future_optimizations/#leistungsoptimierungen-des-anfrage-und-indexierungsprozess","text":"Bei der Integration der einzelnen Sub-Systeme zum Ende des Projektes, ist klar geworden, dass das Gesamtsystem vor allem beim Indexieren kritische Performance Defizite aufweist.","title":"Leistungsoptimierungen des Anfrage- und Indexierungsprozess"},{"location":"outlook/future_optimizations/#das-hauptproblem-bottleneck-netwerk","text":"Das Indexieren einer einzelnen Rede \u00fcber das P2P-Netzwerk ben\u00f6tigte fast eine halbe Stunde. Damit ist uns der vorher erwartete Overhead der hohen Netzwerklast sehr direkt klar geworden und wir haben uns im Projekt gemeinsam dazu entschlossen, Optimierungen vorzunehmen, um den Indexierungsprozess in einer vertretbaren Zeit durchf\u00fchren zu k\u00f6nnen. Zum Vergleich handelte es sich bei der lokalen Ausf\u00fchrung des gleichen Prozesses (also ohne Netzwerk-Overhead) lediglich um Millisekunden. Durch eine Code-Analyse konnten zwei wesentliche Ursachen der Problematik ausgemacht werden. 1. Die Requests von der Volltextsuche zum P2P-Netwerk wurden sequentiell abgearbeitet. * Hier konnten wir erfolgreich optimieren 2. Das P2P-Netzwerk hat, entgegen dem urspr\u00fcnglichen Plan, keine Zusammenf\u00fchrung aller auf einen Peer hinauslaufenden Requests angeboten. * Hier werden grundlegende, architektonische \u00c4nderungen ben\u00f6tigt, die in der \u00fcbrigen Zeit nicht zu schaffen waren","title":"Das Hauptproblem - Bottleneck: Netwerk"},{"location":"outlook/future_optimizations/#losungsansatze","text":"","title":"L\u00f6sungsans\u00e4tze"},{"location":"outlook/future_optimizations/#paralleles-senden-der-requests-aus-der-volltextsuche","text":"Der erste Versuch des Parallelisierens der Requests hat grunds\u00e4tzlich funktioniert, aber zwei weitere Probleme hervogerufen: * Aus der Volltextsuche wurden so viele Requests in so kurzer Zeit gesendet, dass das P2P-Netwerk nach kurzer Zeit \u00fcberlastet war. * Die Fehlerbehandlung innerhalb der Volltextsuche gestaltete sich als wesentlich komplexer gegen\u00fcber der sequentiellen Verarbeitung. Der folgende Ansatz, um diese Probleme in den Griff zu kriegen, war die Implementierung eines Load-Balancers, mit dem versucht wurde das Leistungs-Limit des P2P-Netzwerks auszunutzen, ohne dieses zu \u00fcberlasten und Fehler zu provozieren. Mit diesem Ansatz war es weiterhin sehr schwer, die Fehler anst\u00e4ndig zu behandeln und auch das Finden eines passenden Request-Limits gestaltete sich schwierig. Wesentlich erfolgreicher waren wir mit der Umsetzung der n\u00e4chsten Idee. Diese beruhte darauf, die Indexierung vorerst lokal im Hauptspeicher vorzunehmen und den resultierenden lokal gecachten Index anschlie\u00dfend \u00fcber einen regelm\u00e4\u00dfigen Batch-Job im Hintergrund ins P2P-Netz zu \u00fcbertragen. Der Batch-Job wurde zeitgesteuert angesto\u00dfen und auf separaten Threads ausgef\u00fchrt. Bei jedem Lauf wurde nur eine bestimmte Menge an zu \u00fcbertragenden Postings aus dem lokalen Index gelesen, um die einzelnen Sendedurchl\u00e4ufe m\u00f6glichst kurz zu halten. Sowohl das Sendeintervall, als auch die Menge eines zu sendenden Datenblocks wurde konfigurierbar gestaltet, um beim weiteren Experimentieren problemlos Anpassungen vornehmen zu k\u00f6nnen und die Werte ggF. sogar an die genutzte Umgebung anzupassen. Auch die Fehlerbehandlung lie\u00df sich mit diesem Ansatz leichter angehen. Alle Fehler die beim Senden der Requests vorgekommen sind, wurden entweder als FATAL_ERROR oder als RECOVERABLE_ERROR eingestuft. Die Requests, die fatale Fehler verursacht haben, wurden verworfen, um die Sende-Queue nicht weiter zu blockieren. Die Requests, die nicht fatale Fehler verursachten, wurden mit einem TTL versehen und so lange zur\u00fcck in den lokalen Cache geschrieben, bis deren TTL abgelaufen ist und auch diese Verworfen wurden. Mit diesem Ansatz ist es uns gelungen die Laufzeit der Indexierung einer einzelnen, durchschnittlichen Rede von einer knappen halben Stunde auf unter 3 Minuten zu bringen. Dieses Ergebnis ist immer noch nicht befriedigend, doch f\u00fcr einen einzelnen Optimierungsversuch ein gro\u00dfer Erfolg.","title":"Paralleles Senden der Requests aus der Volltextsuche"},{"location":"outlook/future_optimizations/#minimieren-der-netzwerklast-durch-aggregation-der-requests-pro-peer","text":"Uns war klar, um weitere Leistungsverbesserungen zu erreichen m\u00fcssen wir die Anzahl der Requests minimieren, um das Netzwerk zu entlasten. F\u00fcr dieses Problem war die theoretische L\u00f6sung bereits gegeben, denn sie entspricht dem, was wir urspr\u00fcnglich f\u00fcr das P2P-Netwerk geplant haben. Anstatt f\u00fcr jedes einzelne Posting einen eigenen Request zu senden, m\u00fcssten wir den Hashwert des jeweiligen Postings errechnen und alle Postings, die gemeinsam auf einem Peer gespeichert werden sollen, in einem einzelnen Request zusammenfassen. Die Umsetzung dieses Ansatzes verlangt, tief in die Logik des P2P-Frameworks einzugreifen. Die von uns genutzte Bibliothek f\u00fcr die Implementierung des P2P-Frameworks bot diese M\u00f6glichkeit leider nicht nativ an. Das Austauschen dieser Bibliothek h\u00e4tte zu dem Zeitpunkt zu viel Zeit gekostet und das Umschreiben der Bibliothek auf eigene Faust birgte zu viele Risiken. Wir haben uns dann gemeinsam dazu entschlossen einen anderen Weg zu gehen.","title":"Minimieren der Netzwerklast durch Aggregation der Requests pro Peer"},{"location":"outlook/future_optimizations/#weitere-weniger-kritische-optimierungen","text":"Im Laufe der Entwicklung haben wir einige weitere Optimierungen vorgenommen, wenn immer es angemessen schien. Grunds\u00e4tzlich ist klar geworden, dass in dem von uns gew\u00e4hlten Distibutionsmodell f\u00fcr den Invertierten Index, vorallem die Indexierungsphase Leistungsdefizite aufweist. Die Anfragephase hat wie erwartet wesentlich bessere Performance aufweisen k\u00f6nnen. Dennoch ergab sich auch f\u00fcr die Anfragephase Optimierungspotential: z.B. haben wir unter anderem in der Volltextsuche ein Caching der Suchanfragen implementiert. Wenn immer eine zuvor bereits gestellte Suchanfrage in kurzer Zeit erneut gestellt wurde, hat das System keine vollst\u00e4ndig neue Volltextsuche durchgef\u00fchrt, sondern die gecachte Antwort aus dem letzten Aufruf wiederverwendet. Dieses war vorallem f\u00fcr die Paginierung wichtig, die zwar im UI nicht implementiert wurde, doch in der Volltextsuche bereits voll funktionsf\u00e4hig war. Dieses Caching lie\u00dfe sich noch weiter verbessern, in dem ganze Postinglisten im Hauptspeicher vorgehalten werden w\u00fcrden, um diese auch f\u00fcr vollkommen neue Requests und sogar unabh\u00e4ngig vom aufrufenden Client nutzen zu k\u00f6nnen.","title":"Weitere weniger kritische Optimierungen"},{"location":"outlook/future_optimizations/#fazit","text":"Abschlie\u00dfend l\u00e4sst sich sagen, dass wir mit dem Gesamtergebnis des Projektes und den Erfolgen beim Optimieren sehr zufrieden sind. Die Problemstellung eine Volltextsuche auf Basis eines P2P-Netzwerks zu implementieren birgt viele versteckte Risiken. Zu Beginn des Projektes war in der gesamten Gruppe das Vorwissen eher gering ausgepr\u00e4gt. Wir sind froh, ein funktionierendes Gesamtsystem mit akzeptabler Leisung umgesetzt zu haben und als gesamte Gruppe tiefe Einblicke in die Thematik erlangt zu haben und gro\u00dfe Lernerfolge feiern zu k\u00f6nnen.","title":"Fazit"},{"location":"p2p-dht/about/","text":"p2p-dht This peer-to-peer component is responsible for the distribution of the fulltext-searches posting lists among the peers inside the network. The component is implemented as a DHT based on the libp2p Framework and implemented in NodeJS. In the layer modell it sits between the fulltext-search which is exclusively served by it and above the filesystem which is used for storage. The services provided are: Insertion and retrieval of objects (in our case posting lists) Distributed storage of those objects on multiple nodes in the network","title":"About"},{"location":"p2p-dht/about/#p2p-dht","text":"This peer-to-peer component is responsible for the distribution of the fulltext-searches posting lists among the peers inside the network. The component is implemented as a DHT based on the libp2p Framework and implemented in NodeJS. In the layer modell it sits between the fulltext-search which is exclusively served by it and above the filesystem which is used for storage. The services provided are: Insertion and retrieval of objects (in our case posting lists) Distributed storage of those objects on multiple nodes in the network","title":"p2p-dht"},{"location":"p2p-dht/configure/","text":"Configure Configured via environmental variables in variables.env . See: variables.env.example . HTTP_PORT Port for the http server to run on. Default: 8090 HTTP_LIMIT The maximum request body size. Default: 10mb See: body-parser PEER_PORT Port for the p2p node to run on. Default: 8070 PEER_IP IP for the p2p node to run on. Default: 127.0.0.1 (localhost) PEER_LIST List of peers, required for joining the network. Leave blank on first peer, that is \"creating\" the network. Default: empty Format: - multiaddr incl. ipfs address - seperated by commas Example: PEER_LIST=/ip4/127.0.0.1/tcp/8071/ipfs/QmdW3RF4Yq4acYc4bgUmxeuJQLb2mQpQmMuDTGir5gQcYM, /ip4/127.0.0.1/tcp/8072/ipfs/QmPP5pdu6Dh93DL7LnQkKU2x8m4BoSrQswjQR5q26PMneg You have to fill this list manually with the multiaddresses of the other peers. You do this by configuring a peer through the above options (ports and ip) and running the npm run addr script to show you that specific peers multiaddress, which can then be used in another peers PEER_LIST to connect to this peer. PEER_STORAGE Storage location on disk for the data of the DHT. Default: /tmp/datastore PEER_REDUNDANCY Specifies on how many different remote nodes a value should be stored. Default: 2 PEER_MPLEX_SIZE Specify the max message size of the p2p net's multiplexer . Default: 10mb DEBUG Enable logging in the p2p network. Set it to: libp2p:dht:Q*,libp2p:dht:rpc:get-value:*","title":"Configure"},{"location":"p2p-dht/configure/#configure","text":"Configured via environmental variables in variables.env . See: variables.env.example .","title":"Configure"},{"location":"p2p-dht/configure/#http_port","text":"Port for the http server to run on. Default: 8090","title":"HTTP_PORT"},{"location":"p2p-dht/configure/#http_limit","text":"The maximum request body size. Default: 10mb See: body-parser","title":"HTTP_LIMIT"},{"location":"p2p-dht/configure/#peer_port","text":"Port for the p2p node to run on. Default: 8070","title":"PEER_PORT"},{"location":"p2p-dht/configure/#peer_ip","text":"IP for the p2p node to run on. Default: 127.0.0.1 (localhost)","title":"PEER_IP"},{"location":"p2p-dht/configure/#peer_list","text":"List of peers, required for joining the network. Leave blank on first peer, that is \"creating\" the network. Default: empty Format: - multiaddr incl. ipfs address - seperated by commas Example: PEER_LIST=/ip4/127.0.0.1/tcp/8071/ipfs/QmdW3RF4Yq4acYc4bgUmxeuJQLb2mQpQmMuDTGir5gQcYM, /ip4/127.0.0.1/tcp/8072/ipfs/QmPP5pdu6Dh93DL7LnQkKU2x8m4BoSrQswjQR5q26PMneg You have to fill this list manually with the multiaddresses of the other peers. You do this by configuring a peer through the above options (ports and ip) and running the npm run addr script to show you that specific peers multiaddress, which can then be used in another peers PEER_LIST to connect to this peer.","title":"PEER_LIST"},{"location":"p2p-dht/configure/#peer_storage","text":"Storage location on disk for the data of the DHT. Default: /tmp/datastore","title":"PEER_STORAGE"},{"location":"p2p-dht/configure/#peer_redundancy","text":"Specifies on how many different remote nodes a value should be stored. Default: 2","title":"PEER_REDUNDANCY"},{"location":"p2p-dht/configure/#peer_mplex_size","text":"Specify the max message size of the p2p net's multiplexer . Default: 10mb","title":"PEER_MPLEX_SIZE"},{"location":"p2p-dht/configure/#debug","text":"Enable logging in the p2p network. Set it to: libp2p:dht:Q*,libp2p:dht:rpc:get-value:*","title":"DEBUG"},{"location":"p2p-dht/design/","text":"Design Framework Choice and Data Distribution Design How the inverted index should be distributed with the DHT Original Plan Indexing Initally the plan we developed was to have the crawler send the extracted and structured documents to it's local full-text-search, which would break it up and assemble groups of keywords. Those groups of keywords are to be split up accross the p2p network, turned into an inverted index and persisted with the dht. Retrieval The posting lists of the inverted index are available to the full-text-search component through an http server, which answers the UI's queries for searches. Choosing a p2p library I had decided that libp2p would be the p2p framework to be used, as it fullfilled all the other demands of the project: net and routing (different configurable ways to run/setup the network) content routing (put/get using key-value pairs) static connection addresses well maintained and documented efficient transports well tested with checks and corrections throughout to maintain consistent state and functionality It was preferable to: using a smaller (and/or outdated) library that didn't cover the demands above building the system from the ground up, for which the timeframe would be tight and it probably would not reach libp2p's level of consistency libp2p's Constraints One constraint that comes along with using libp2p is that the put separates local and remote insertion. Looking at the implementation of put it always inserts locally and then remotely into the network. This is not to our specification as we did not want to make a distinction between local and remote but just wanted to insert on the peer(s) closest to the hashed key of the value to be inserted. Possible changes to the design to address this 1. local & remote Keep current design and use the given implementation to insert once locally and n-times remotely. Pro: - scalable: the processing of keywords -> posting lists happens distributed accross the network Contra: - suboptimal inverted index distribution: the algorithm used in the full-text-search component - to divvy up the keywords to different peers for computation - would be responsible for distribution the local part of the data accross the network - no separation of concerns: again the algorithm just mentioned handles functionality that should be part of the p2p net 2. remote only Designate a peer to become the central crawler and inserter instance and only insert remotely. Pro: - optimal inverted index distribution: by inserted in the closest peer, to the specification of kademlia this would be the most optimal distribution of the data accross the network - simple implementation: least effort to implement (no balancing algorithm in full-text-search, trivial adjustment in the framework) Contra: - not scalable: to have all the computation of creating the index done on a single peer has a natural limit and is not an efficient use of the networks resources - resource imbalance: increased data load on the rest of the peers, storage resources unused (hd and cpu (see previous point)) - single point of failure: not critial though, as the indexing only happens upfront and very occasionally throughout service 3. local/remote Fork the framework and adjust it to do local and remote put/get through the same routines. This would be the optimal solution and satifies the original design. Pro: - optimal inverted index distribution: same as with 2. - optimal resource usage: storage and cpu load are distributed equally - scalable: same as with 1. Contra: - stability/introduction of inconsistencies: requires heavy modification of the framework, which will possibly circumvent checks and corrections within it and produce a less stable framework as a result - a lot of work: most effort by far, I tried implementing this and hit one hurdle after another, the underlying system (kademlia and k-buckets below libp2p) definitely allow for this change, but you are just fighting against libp2p at every point Our choice We decided upon moving forward with \"remote only\" (2.) as the downsides are very much tolerable along with having the best of both words on the pro side. API Specification As defined here . openapi: 3.1.0 info: title: P2P framework version: 0.2 paths: /:key: get: summary: Get an entry from hash table description: data is an array parameters: - name: key in: path responses: \"200\": description: OK content: schema: format: error: \"boolean\" key: \"string\" value: \"any[]\" example: error: false key: \"Grundgesetz\" value: [ \"postingList1\", \"postingList2\" ] \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"No key given\" /append/:key: put: summary: Append to an entry in the hash table description: Entities are an array, to which you can add a single value through this route parameters: - name: key in: path - name: data in: body schema: format: data: \"any\" example: data: { id: 123 } responses: \"200\": description: OK content: schema: format: error: \"boolean\" key: \"string\" example: error: false key: \"Grundgesetz\" \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"missing data\" /merge/:key: put: summary: Merge with the array in the hash table description: Entities are an array, to which you can add a mutiple values through this route by wrapping them in an array parameters: - name: key in: path - name: data in: body schema: format: data: \"any[]\" example: data: [ { id: 123 }, { id: 124 } ] responses: \"200\": description: OK content: schema: format: error: \"boolean\" key: \"string\" example: error: false key: \"Grundgesetz\" \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"missing data\" /batch-get: post: summary: Get multiple entries of the hash table description: parameters: - name: keys in: body schema: format: data: \"string[]\" responses: \"200\": description: OK content: schema: format: error: \"boolean\" keys: \"string[]\" values: \"object\" example: error: false keys: [ \"Grundgesetz\", \"Merkel\" ] values: { \"Grungesetz\": { \"error\": false, \"value\": [ \"postingList1\", \"postingList2\" ] }, \"Merkel\": { \"error\": true, \"errorMsg\": \"Not found\" } \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"missing keys\" Also there is a key mangaged by the system named _keyset_size , which tracks the number of keysets in the dht. API Examples Setup to run the examples ./spawnnode 1 & #=> Server running on http://localhost:8091 ./spawnnode 2 & #=> Server running on http://localhost:8092 ./spawnnode 3 & #=> Server running on http://localhost:8093 PUT /append/:key curl -Ss -X PUT \"http://localhost:8093/append/linux\" -d '{\"data\":\"arch\"}' -H \"Content-Type: application/json\" curl -Ss -X PUT \"http://localhost:8093/append/linux\" -d '{\"data\":\"debian\"}' -H \"Content-Type: application/json\" { \"error\": false, \"key\": \"linux\" } PUT /merge/:key curl -Ss -X PUT \"http://localhost:8093/merge/linux\" -d '{\"data\":[\"ubuntu\",\"manjaro\"]}' -H \"Content-Type: application/json\" { \"error\": false, \"key\": \"linux\" } GET /:key curl -Ss \"http://localhost:8091/linux\" { \"error\": false, \"key\": \"linux\", \"value\": [ \"arch\", \"debian\", \"ubuntu\", \"manjaro\" ] } POST /batch-get curl -Ss -X POST \"http://localhost:8092/batch-get\" -d '{\"keys\":[\"linux\",\"windows\"]}' -H \"Content-Type: application/json\" { \"error\": false, \"keys\": [ \"linux\", \"windows\" ], \"values\": { \"linux\": { \"error\": false, \"value\": [ \"arch\", \"debian\", \"ubuntu\", \"manjaro\" ] }, \"windows\": { \"error\": true, \"errorMsg\": \"Not found\" } } }","title":"Design"},{"location":"p2p-dht/design/#design","text":"","title":"Design"},{"location":"p2p-dht/design/#framework-choice-and-data-distribution-design","text":"How the inverted index should be distributed with the DHT","title":"Framework Choice and Data Distribution Design"},{"location":"p2p-dht/design/#original-plan","text":"Indexing Initally the plan we developed was to have the crawler send the extracted and structured documents to it's local full-text-search, which would break it up and assemble groups of keywords. Those groups of keywords are to be split up accross the p2p network, turned into an inverted index and persisted with the dht. Retrieval The posting lists of the inverted index are available to the full-text-search component through an http server, which answers the UI's queries for searches.","title":"Original Plan"},{"location":"p2p-dht/design/#choosing-a-p2p-library","text":"I had decided that libp2p would be the p2p framework to be used, as it fullfilled all the other demands of the project: net and routing (different configurable ways to run/setup the network) content routing (put/get using key-value pairs) static connection addresses well maintained and documented efficient transports well tested with checks and corrections throughout to maintain consistent state and functionality It was preferable to: using a smaller (and/or outdated) library that didn't cover the demands above building the system from the ground up, for which the timeframe would be tight and it probably would not reach libp2p's level of consistency","title":"Choosing a p2p library"},{"location":"p2p-dht/design/#libp2ps-constraints","text":"One constraint that comes along with using libp2p is that the put separates local and remote insertion. Looking at the implementation of put it always inserts locally and then remotely into the network. This is not to our specification as we did not want to make a distinction between local and remote but just wanted to insert on the peer(s) closest to the hashed key of the value to be inserted.","title":"libp2p's Constraints"},{"location":"p2p-dht/design/#possible-changes-to-the-design-to-address-this","text":"","title":"Possible changes to the design to address this"},{"location":"p2p-dht/design/#1-local-remote","text":"Keep current design and use the given implementation to insert once locally and n-times remotely. Pro: - scalable: the processing of keywords -> posting lists happens distributed accross the network Contra: - suboptimal inverted index distribution: the algorithm used in the full-text-search component - to divvy up the keywords to different peers for computation - would be responsible for distribution the local part of the data accross the network - no separation of concerns: again the algorithm just mentioned handles functionality that should be part of the p2p net","title":"1. local &amp; remote"},{"location":"p2p-dht/design/#2-remote-only","text":"Designate a peer to become the central crawler and inserter instance and only insert remotely. Pro: - optimal inverted index distribution: by inserted in the closest peer, to the specification of kademlia this would be the most optimal distribution of the data accross the network - simple implementation: least effort to implement (no balancing algorithm in full-text-search, trivial adjustment in the framework) Contra: - not scalable: to have all the computation of creating the index done on a single peer has a natural limit and is not an efficient use of the networks resources - resource imbalance: increased data load on the rest of the peers, storage resources unused (hd and cpu (see previous point)) - single point of failure: not critial though, as the indexing only happens upfront and very occasionally throughout service","title":"2. remote only"},{"location":"p2p-dht/design/#3-localremote","text":"Fork the framework and adjust it to do local and remote put/get through the same routines. This would be the optimal solution and satifies the original design. Pro: - optimal inverted index distribution: same as with 2. - optimal resource usage: storage and cpu load are distributed equally - scalable: same as with 1. Contra: - stability/introduction of inconsistencies: requires heavy modification of the framework, which will possibly circumvent checks and corrections within it and produce a less stable framework as a result - a lot of work: most effort by far, I tried implementing this and hit one hurdle after another, the underlying system (kademlia and k-buckets below libp2p) definitely allow for this change, but you are just fighting against libp2p at every point","title":"3. local/remote"},{"location":"p2p-dht/design/#our-choice","text":"We decided upon moving forward with \"remote only\" (2.) as the downsides are very much tolerable along with having the best of both words on the pro side.","title":"Our choice"},{"location":"p2p-dht/design/#api-specification","text":"As defined here . openapi: 3.1.0 info: title: P2P framework version: 0.2 paths: /:key: get: summary: Get an entry from hash table description: data is an array parameters: - name: key in: path responses: \"200\": description: OK content: schema: format: error: \"boolean\" key: \"string\" value: \"any[]\" example: error: false key: \"Grundgesetz\" value: [ \"postingList1\", \"postingList2\" ] \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"No key given\" /append/:key: put: summary: Append to an entry in the hash table description: Entities are an array, to which you can add a single value through this route parameters: - name: key in: path - name: data in: body schema: format: data: \"any\" example: data: { id: 123 } responses: \"200\": description: OK content: schema: format: error: \"boolean\" key: \"string\" example: error: false key: \"Grundgesetz\" \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"missing data\" /merge/:key: put: summary: Merge with the array in the hash table description: Entities are an array, to which you can add a mutiple values through this route by wrapping them in an array parameters: - name: key in: path - name: data in: body schema: format: data: \"any[]\" example: data: [ { id: 123 }, { id: 124 } ] responses: \"200\": description: OK content: schema: format: error: \"boolean\" key: \"string\" example: error: false key: \"Grundgesetz\" \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"missing data\" /batch-get: post: summary: Get multiple entries of the hash table description: parameters: - name: keys in: body schema: format: data: \"string[]\" responses: \"200\": description: OK content: schema: format: error: \"boolean\" keys: \"string[]\" values: \"object\" example: error: false keys: [ \"Grundgesetz\", \"Merkel\" ] values: { \"Grungesetz\": { \"error\": false, \"value\": [ \"postingList1\", \"postingList2\" ] }, \"Merkel\": { \"error\": true, \"errorMsg\": \"Not found\" } \"400\": description: User error content: schema: format: error: \"boolean\" errorMsg: \"string\" example: error: true errorMsg: \"missing keys\" Also there is a key mangaged by the system named _keyset_size , which tracks the number of keysets in the dht.","title":"API Specification"},{"location":"p2p-dht/design/#api-examples","text":"","title":"API Examples"},{"location":"p2p-dht/design/#setup-to-run-the-examples","text":"./spawnnode 1 & #=> Server running on http://localhost:8091 ./spawnnode 2 & #=> Server running on http://localhost:8092 ./spawnnode 3 & #=> Server running on http://localhost:8093","title":"Setup to run the examples"},{"location":"p2p-dht/design/#put-appendkey","text":"curl -Ss -X PUT \"http://localhost:8093/append/linux\" -d '{\"data\":\"arch\"}' -H \"Content-Type: application/json\" curl -Ss -X PUT \"http://localhost:8093/append/linux\" -d '{\"data\":\"debian\"}' -H \"Content-Type: application/json\" { \"error\": false, \"key\": \"linux\" }","title":"PUT /append/:key"},{"location":"p2p-dht/design/#put-mergekey","text":"curl -Ss -X PUT \"http://localhost:8093/merge/linux\" -d '{\"data\":[\"ubuntu\",\"manjaro\"]}' -H \"Content-Type: application/json\" { \"error\": false, \"key\": \"linux\" }","title":"PUT /merge/:key"},{"location":"p2p-dht/design/#get-key","text":"curl -Ss \"http://localhost:8091/linux\" { \"error\": false, \"key\": \"linux\", \"value\": [ \"arch\", \"debian\", \"ubuntu\", \"manjaro\" ] }","title":"GET /:key"},{"location":"p2p-dht/design/#post-batch-get","text":"curl -Ss -X POST \"http://localhost:8092/batch-get\" -d '{\"keys\":[\"linux\",\"windows\"]}' -H \"Content-Type: application/json\" { \"error\": false, \"keys\": [ \"linux\", \"windows\" ], \"values\": { \"linux\": { \"error\": false, \"value\": [ \"arch\", \"debian\", \"ubuntu\", \"manjaro\" ] }, \"windows\": { \"error\": true, \"errorMsg\": \"Not found\" } } }","title":"POST /batch-get"},{"location":"p2p-dht/run/","text":"Run Install: npm install Development: npm start Production: npm run start-prod","title":"Run"},{"location":"p2p-dht/run/#run","text":"Install: npm install Development: npm start Production: npm run start-prod","title":"Run"},{"location":"p2p-dht/scripts/","text":"Scripts Multiaddress: Print the multiaddress used for connection to the node: npm run addr Debug: Print the environmental variables that are being read in: npm run debug Node testing: Run a node for testing: npm run spawn 1 Generate peerId locally: Create the peerId.json locally. npm run local-peerid","title":"Scripts"},{"location":"p2p-dht/scripts/#scripts","text":"Multiaddress: Print the multiaddress used for connection to the node: npm run addr Debug: Print the environmental variables that are being read in: npm run debug Node testing: Run a node for testing: npm run spawn 1 Generate peerId locally: Create the peerId.json locally. npm run local-peerid","title":"Scripts"},{"location":"textextraction-18/build_jar_file/","text":"Build Jar File mvn clean package","title":"Build Jar File"},{"location":"textextraction-18/build_jar_file/#build-jar-file","text":"mvn clean package","title":"Build Jar File"},{"location":"textextraction-18/execute/","text":"Execute java -jar textextraction-18.jar \\<plenary minutes xml file> creates a json file from the plenary minutes with all entered speeches","title":"Execute"},{"location":"textextraction-18/execute/#execute","text":"java -jar textextraction-18.jar \\<plenary minutes xml file> creates a json file from the plenary minutes with all entered speeches","title":"Execute"},{"location":"textextraction-18/problems/","text":"Problems Most of the problems arose from the assumption that there was consistency in the formatting of the documents. Problem Description Document type In the 1st - 14th electoral legislature period, a document type was given to the XML files, but from the from the 15th electoral legislature onwards, this was no longer the case. Formatting In some documents, the considered commonalities of the table of contents were also not present, which makes a uniform programme for all electoral legislatures almost impossible. Naming of the affiliation There were also many spelling differences in the naming of affiliations. The best example of this is the party \"BUNDNIS 90/DIE GR\u00dcNEN\". For the different spellings of this party alone: B\u00dcNDNIS 90/DIE GR\u00dcNEN B\u00dcNDNIS 90/ DIE GR\u00dcNEN B\u00dcNDNIS 90 /DIE GR\u00dcNEN B\u00dcNDNIS 90/DIE GR\u00dc- NEN three regular printouts had to be changed to make them work. The decisive point in the extraction was the search in the table of contents for persons. Within the search itself, however, there were differences that had to be processed separately. The search was implemented with the method createMap() in the SpeechSearch class. The literal flow of the method is roughly as follows: IF there is a title the first name is also contained in the same entry and must be saved after that, each entry is a name, until the entry that contains a title. Next loop pass from this title. otherwise if a title is followed by a name then each subsequent entry is a name and must be saved, until an entry contains a title. next loop pass from this title. If the speakers were found for each title, these entries are saved in a map.","title":"Problems"},{"location":"textextraction-18/problems/#problems","text":"Most of the problems arose from the assumption that there was consistency in the formatting of the documents. Problem Description Document type In the 1st - 14th electoral legislature period, a document type was given to the XML files, but from the from the 15th electoral legislature onwards, this was no longer the case. Formatting In some documents, the considered commonalities of the table of contents were also not present, which makes a uniform programme for all electoral legislatures almost impossible. Naming of the affiliation There were also many spelling differences in the naming of affiliations. The best example of this is the party \"BUNDNIS 90/DIE GR\u00dcNEN\". For the different spellings of this party alone: B\u00dcNDNIS 90/DIE GR\u00dcNEN B\u00dcNDNIS 90/ DIE GR\u00dcNEN B\u00dcNDNIS 90 /DIE GR\u00dcNEN B\u00dcNDNIS 90/DIE GR\u00dc- NEN three regular printouts had to be changed to make them work. The decisive point in the extraction was the search in the table of contents for persons. Within the search itself, however, there were differences that had to be processed separately. The search was implemented with the method createMap() in the SpeechSearch class. The literal flow of the method is roughly as follows: IF there is a title the first name is also contained in the same entry and must be saved after that, each entry is a name, until the entry that contains a title. Next loop pass from this title. otherwise if a title is followed by a name then each subsequent entry is a name and must be saved, until an entry contains a title. next loop pass from this title. If the speakers were found for each title, these entries are saved in a map.","title":"Problems"},{"location":"textextraction-18/textextraction-18/","text":"Textextraction-18 The content-related task of the text extraction-18 was to extract all speeches of the 1st - 18th legislative period, the XML documents passed by the crawler and output them in JSON files. The crawler achieved this by temporarily persisting the plenary minutes as as XML files and passing them as parameters to the text extraction-18. The basic idea is to examine the text block semantically and syntactically in order to find a search algorithm, which will find the text within the text block: \u25cf Title of the speech \u25cf Name of the speaker \u25cf Affiliation \u25cf Date of the speech \u25cf Speech to a person and extracts it.","title":"About"},{"location":"textextraction-18/textextraction-18/#textextraction-18","text":"The content-related task of the text extraction-18 was to extract all speeches of the 1st - 18th legislative period, the XML documents passed by the crawler and output them in JSON files. The crawler achieved this by temporarily persisting the plenary minutes as as XML files and passing them as parameters to the text extraction-18. The basic idea is to examine the text block semantically and syntactically in order to find a search algorithm, which will find the text within the text block: \u25cf Title of the speech \u25cf Name of the speaker \u25cf Affiliation \u25cf Date of the speech \u25cf Speech to a person and extracts it.","title":"Textextraction-18"},{"location":"textextraction-19/about/","text":"Text-Extraktion von Bundestagsreden der 19. Legislaturperiode Nimmt Plenarprotokolle der 19. Legislaturperiode oder sp\u00e4teren im XML-Format entgegen und gibt eine JSON-Datei mit Reden aus dem Protokoll zur\u00fcck.","title":"\u00dcber"},{"location":"textextraction-19/about/#text-extraktion-von-bundestagsreden-der-19-legislaturperiode","text":"Nimmt Plenarprotokolle der 19. Legislaturperiode oder sp\u00e4teren im XML-Format entgegen und gibt eine JSON-Datei mit Reden aus dem Protokoll zur\u00fcck.","title":"Text-Extraktion von Bundestagsreden der 19. Legislaturperiode"},{"location":"textextraction-19/anforderungen/","text":"Anforderungen Python 3.9","title":"Anforderungen"},{"location":"textextraction-19/anforderungen/#anforderungen","text":"Python 3.9","title":"Anforderungen"},{"location":"textextraction-19/format/","text":"Format der zur\u00fcckgegebenen JSON-Datei { //Tagesordnungspunkt \"title\": \"string\", //Gek\u00fcrzte Version des Titels \"title_short\": \"string\", //Redner \"speaker\": \"string\", //Zugeh\u00f6rigkeit: entweder Partei oder Amt, so wie im Protokoll vorhanden \"affiliation\": \"string\", //Datum der Rede \"date\": \"Date in ISO 8601-1:2019 String Format\", //Gesamter Inhalt der Rede \"text\": \"string\" }","title":"Format der zur\u00fcckgegebenen JSON-Datei"},{"location":"textextraction-19/format/#format-der-zuruckgegebenen-json-datei","text":"{ //Tagesordnungspunkt \"title\": \"string\", //Gek\u00fcrzte Version des Titels \"title_short\": \"string\", //Redner \"speaker\": \"string\", //Zugeh\u00f6rigkeit: entweder Partei oder Amt, so wie im Protokoll vorhanden \"affiliation\": \"string\", //Datum der Rede \"date\": \"Date in ISO 8601-1:2019 String Format\", //Gesamter Inhalt der Rede \"text\": \"string\" }","title":"Format der zur\u00fcckgegebenen JSON-Datei"},{"location":"textextraction-19/nutzung/","text":"Nutzung python text-extraction-19 <Plenarprotocol xml-file> erzeugt eine JSON-Datei mit dem gleichen Namen im gleichen Ordner, die alle Reden des Protokolls enth\u00e4lt. python title_shortener <speech json-file> f\u00fcgt gek\u00fcrzte Titel zu einer bereits existierenden JSON-Datei, falls nicht bereits vorhanden.","title":"Nutzung"},{"location":"textextraction-19/nutzung/#nutzung","text":"python text-extraction-19 <Plenarprotocol xml-file> erzeugt eine JSON-Datei mit dem gleichen Namen im gleichen Ordner, die alle Reden des Protokolls enth\u00e4lt. python title_shortener <speech json-file> f\u00fcgt gek\u00fcrzte Titel zu einer bereits existierenden JSON-Datei, falls nicht bereits vorhanden.","title":"Nutzung"},{"location":"textextraction-19/titel_der_reden/","text":"Titel der Reden Da Bundestagsreden im Protokoll keine traditionellen Titel haben, wurde entschieden, die jeweiligen Tagesordnungspunkte als Titel zu verwenden. Da diese teilweise unverh\u00e4ltnism\u00e4\u00dfig lang sind, wurde eine Funktionalit\u00e4t zur K\u00fcrzung der Titel hinzugef\u00fcgt. In manchen F\u00e4llen werden meherere Tagesordnungspunkte in Verbindung miteinander abgearbeitet. In diesem Fall enth\u00e4lt der gek\u00fcrzte Titel nur die gek\u00fcrzte Version des erstgenannten Tagesordnungspunktes.","title":"Titel der Reden"},{"location":"textextraction-19/titel_der_reden/#titel-der-reden","text":"Da Bundestagsreden im Protokoll keine traditionellen Titel haben, wurde entschieden, die jeweiligen Tagesordnungspunkte als Titel zu verwenden. Da diese teilweise unverh\u00e4ltnism\u00e4\u00dfig lang sind, wurde eine Funktionalit\u00e4t zur K\u00fcrzung der Titel hinzugef\u00fcgt. In manchen F\u00e4llen werden meherere Tagesordnungspunkte in Verbindung miteinander abgearbeitet. In diesem Fall enth\u00e4lt der gek\u00fcrzte Titel nur die gek\u00fcrzte Version des erstgenannten Tagesordnungspunktes.","title":"Titel der Reden"},{"location":"user_interface/l%C3%B6sungsansatz/","text":"L\u00f6sungsansatz Die Benutzeroberfl\u00e4che wird als React-Web-Applikation mit Javascript umgesetzt. React basiert darauf, die Website in Komponenten zu zerlegen und diese gegebenenfalls wiederverwendbar zu machen. Zus\u00e4tzlich wurde CSS f\u00fcr das Styling der Komponenten benutzt. Ein dynamisches, erweiterbares Formular soll m\u00f6glichst genaue Suchanfragen erm\u00f6glichen. Urspr\u00fcnglich sollten neue Formularreihen hinzugef\u00fcgt werden bei denen man einen logischen Operator sowie Typ (Freie Suche, Partei, Redner) frei ausw\u00e4hlen kann. Aus diesem Formular wird eine Query erstellt, die dann an die Volltextsuche geschickt wird. Die Volltextsuche gibt unter anderem Dokumenten-Ids zur\u00fcck anhand derer aus der MongoDB die Reden mit Metadaten angefragt werden k\u00f6nnen. Die Anzeige der Ergebnisse wird als Ergebnisliste umgesetzt, bei Klick auf einen Listeneintrag wird die volle Rede angezeigt.","title":"L\u00f6sungsansatz"},{"location":"user_interface/l%C3%B6sungsansatz/#losungsansatz","text":"Die Benutzeroberfl\u00e4che wird als React-Web-Applikation mit Javascript umgesetzt. React basiert darauf, die Website in Komponenten zu zerlegen und diese gegebenenfalls wiederverwendbar zu machen. Zus\u00e4tzlich wurde CSS f\u00fcr das Styling der Komponenten benutzt. Ein dynamisches, erweiterbares Formular soll m\u00f6glichst genaue Suchanfragen erm\u00f6glichen. Urspr\u00fcnglich sollten neue Formularreihen hinzugef\u00fcgt werden bei denen man einen logischen Operator sowie Typ (Freie Suche, Partei, Redner) frei ausw\u00e4hlen kann. Aus diesem Formular wird eine Query erstellt, die dann an die Volltextsuche geschickt wird. Die Volltextsuche gibt unter anderem Dokumenten-Ids zur\u00fcck anhand derer aus der MongoDB die Reden mit Metadaten angefragt werden k\u00f6nnen. Die Anzeige der Ergebnisse wird als Ergebnisliste umgesetzt, bei Klick auf einen Listeneintrag wird die volle Rede angezeigt.","title":"L\u00f6sungsansatz"},{"location":"user_interface/probleme/","text":"Probleme Das Design des Suchformulars musste abge\u00e4ndert werden, da aufgrund des Aufbaus nicht genau klar war, in welcher Reihenfolge beziehungsweise mit welcher Priorit\u00e4t einzelne Formularreihen ausgewertet werden. Infolgedessen wurde das Suchformular in drei Hauptbereiche eingeteilt: Freie Suche sowie Partei und Redner, die letzteren beiden bieten jedoch keine Auswahl eines logischen Operators mehr an. Im Laufe des Projekts wurde klar, dass au\u00dferdem ein Backend f\u00fcr den Zugriff auf die MongoDB n\u00f6tig ist, da ein direkter Zugriff aus dem UI nicht m\u00f6glich ist. Es wurde als simples Node.js Projekt aufgesetzt, das eine GET-Request mit Dokumenten-Id als \u00dcbergabeparameter beantworten kann. Anfangs war eine Sortierung der Suchergebnisse in Diskussion, diese wurde aber bewusst weggelassen, da die Suchergebnisse standardm\u00e4\u00dfig nach Relevanz sortiert von der Volltextsuche zur\u00fcckgegeben werden. Eine alphabetisches Sortieren nach Partei oder Titel der Reden erschien obsolet. Durch die Komplexit\u00e4t der Titel wird bei einer alphabetischen Sortierung kein Mehrwert geboten.","title":"Probleme"},{"location":"user_interface/probleme/#probleme","text":"Das Design des Suchformulars musste abge\u00e4ndert werden, da aufgrund des Aufbaus nicht genau klar war, in welcher Reihenfolge beziehungsweise mit welcher Priorit\u00e4t einzelne Formularreihen ausgewertet werden. Infolgedessen wurde das Suchformular in drei Hauptbereiche eingeteilt: Freie Suche sowie Partei und Redner, die letzteren beiden bieten jedoch keine Auswahl eines logischen Operators mehr an. Im Laufe des Projekts wurde klar, dass au\u00dferdem ein Backend f\u00fcr den Zugriff auf die MongoDB n\u00f6tig ist, da ein direkter Zugriff aus dem UI nicht m\u00f6glich ist. Es wurde als simples Node.js Projekt aufgesetzt, das eine GET-Request mit Dokumenten-Id als \u00dcbergabeparameter beantworten kann. Anfangs war eine Sortierung der Suchergebnisse in Diskussion, diese wurde aber bewusst weggelassen, da die Suchergebnisse standardm\u00e4\u00dfig nach Relevanz sortiert von der Volltextsuche zur\u00fcckgegeben werden. Eine alphabetisches Sortieren nach Partei oder Titel der Reden erschien obsolet. Durch die Komplexit\u00e4t der Titel wird bei einer alphabetischen Sortierung kein Mehrwert geboten.","title":"Probleme"},{"location":"user_interface/problemstellung/","text":"Problemstellung Die UI soll die Eingabe von pr\u00e4zisen Suchanfragen zu den Bundestagsreden erm\u00f6glichen, die Suchergebnisse mit ihren Metadaten anzeigen und beim Klick auf eine einzelne Rede den vollen Text anzeigen. Hierbei gab es keine Vorgaben zur technischen Umsetzung.","title":"Problemstellung"},{"location":"user_interface/problemstellung/#problemstellung","text":"Die UI soll die Eingabe von pr\u00e4zisen Suchanfragen zu den Bundestagsreden erm\u00f6glichen, die Suchergebnisse mit ihren Metadaten anzeigen und beim Klick auf eine einzelne Rede den vollen Text anzeigen. Hierbei gab es keine Vorgaben zur technischen Umsetzung.","title":"Problemstellung"},{"location":"user_interface/schlussbetrachtung/","text":"Schlussbetrachtung Die Anforderungen wurden weitestgehend erf\u00fcllt. Aus Zeitmangel wurden ein paar optionale Features nicht mehr angeboten, wie zum Beispiel Paginierung und das Anzeigen von sinnvollen Textausschnitten in der Suchergebnisliste.","title":"Schlussbetrachtung"},{"location":"user_interface/schlussbetrachtung/#schlussbetrachtung","text":"Die Anforderungen wurden weitestgehend erf\u00fcllt. Aus Zeitmangel wurden ein paar optionale Features nicht mehr angeboten, wie zum Beispiel Paginierung und das Anzeigen von sinnvollen Textausschnitten in der Suchergebnisliste.","title":"Schlussbetrachtung"},{"location":"user_interface/verwendung_der_software/","text":"Verwendung der Software F\u00fcr volle Funktionalit\u00e4t muss das User Interface \u00fcber das Ops gestartet werden. F\u00fcr die Nutzung des User Interface ben\u00f6tigt man Node.js . Das User Interface ist intern in Frontend und Backend aufgeteilt, diese m\u00fcssen wenn man sie lokal und alleinstehend ausf\u00fchren will seperat gestartet werden. Das Frontend wurde mit Create-React-App initialisiert und l\u00e4sst sich z.B. mit dem Befehl npm start im \"frontend\" Ordner starten. Das Backend ist eine simple Node.js Anwendung das sich mit dem Befehl node index.js im \"backend\" Ordner starten l\u00e4sst. Es stellt einen Endpunkt f\u00fcr einen GET-Request bereit, dieser kann folgenderma\u00dfen http://{hostadress}:{hostport}/api/protocol/doc_id erreicht werden und gibt das Protokoll mit der passenden doc_id zur\u00fcck, falls dieses gefunden wurde.","title":"Verwendung der Software"},{"location":"user_interface/verwendung_der_software/#verwendung-der-software","text":"F\u00fcr volle Funktionalit\u00e4t muss das User Interface \u00fcber das Ops gestartet werden. F\u00fcr die Nutzung des User Interface ben\u00f6tigt man Node.js . Das User Interface ist intern in Frontend und Backend aufgeteilt, diese m\u00fcssen wenn man sie lokal und alleinstehend ausf\u00fchren will seperat gestartet werden. Das Frontend wurde mit Create-React-App initialisiert und l\u00e4sst sich z.B. mit dem Befehl npm start im \"frontend\" Ordner starten. Das Backend ist eine simple Node.js Anwendung das sich mit dem Befehl node index.js im \"backend\" Ordner starten l\u00e4sst. Es stellt einen Endpunkt f\u00fcr einen GET-Request bereit, dieser kann folgenderma\u00dfen http://{hostadress}:{hostport}/api/protocol/doc_id erreicht werden und gibt das Protokoll mit der passenden doc_id zur\u00fcck, falls dieses gefunden wurde.","title":"Verwendung der Software"}]}